<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Zehui Chen</title>
    <description>~</description>
    <link>http://localhost:4000</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
    
      <item>
        <title>写在实习结束之际</title>
        <description>&lt;p&gt;这周差不多就是在图森待的最后一周啦，有些舍不得..&lt;/p&gt;

&lt;p&gt;…&lt;/p&gt;

&lt;p&gt;…&lt;/p&gt;

&lt;p&gt;…&lt;/p&gt;

&lt;p&gt;公司给的三台八卡机😭&lt;/p&gt;

&lt;p&gt;哈哈哈，其实很多时候机缘巧合的事情真的很多，如果当初过了自动化所的筛选，说不定现在在跟着zyq弄GNN，如果当初没面到图森的实习，可能现在本科就业准备写工程了。在进入图森之前，我几乎没有任何CNN相关的知识，除了跟着Ng的课过了一遍CNN外，连ResNet的具体结构都不是太了解。你问我怎么面进的图森？哈，我也不知道，但是图森实习岗的bar真的不高呢！想来图森的同学可以找我内推呀～&lt;/p&gt;

&lt;p&gt;记得入职第一天的时候，naiyan把我安排在了他座位正后面，整天在dalao后面工作感觉🍐山大，不过后来就好了，还经常跟naiyan吃🐔～我在图森待了大概9～10个月左右，期间做了不少工作，虽然还是没有做出一项任何能够发表的工作，这也是我最遗憾的事情，从大二开始到现在，摸爬滚打从表征学习到目标检测，依然没有能够生产出一篇看的过去的文章。或许是运气和实力都还不够吧，也许本科发顶会并不是我这种人可以做到的吧，我一直是一个普普通通的人而已，希望能够在硕士期间做出点工作来吧～&lt;/p&gt;

&lt;p&gt;在图森的这几个月尝试了挺多东西，也学到了很多，从刚进公司开始复现Mask Scoring RCNN，到后来在crowd场景下的一些尝试，包括mask nms（这个东西其实最后被自然而然的揉到了SOLO这类bbox free的ins seg框架中，还有一个proposal出多个框，当时真的离crowddet很近了，只差没有想到EMD loss这么简单明了的方式，同时也是因为一直没有把crowdhuman复现出来差不多的点（后来发现是因为cocotools默认每张图最多出100个框，以及算分的时候也要考虑ignore region）。后面又尝试了一些关于uncertainty的idea，也最终由于效果不是很理想最终放弃。其实也尝试过不少idea，但都或许是由于自己能力不够或者思路不够准确而最终放弃。当时也觉得很自闭，试了很多东西都不work，甚至开始否定自己，每天都活在某种阴影下。但是现在回过头来看，虽然确实没有获得显式的成果，但是也积累了很多经验和知识，包括验证一个idea的时候，我们是不是可以先从上界的角度来看究竟有多可行？对于crowd场景该如何解决？以及目标检测中的不确定性问题等等我都或多或少有了一点自己的思考。比起原本在paper reading时只能半懂不懂的听dalao们分享paper，现在的我最喜欢这个环节，能够学到很多东西，不仅是最近paper的一些idea，也是不断锻炼如何将一篇paper给陈述清楚的能力。当然这里也很感谢qf这位公司里唯一跟我方向相同的实习生（一起做2D Detection的，虽然是寒假结束才来的），他是个超级上进的人，周六周日都来公司写代码，之前就曾在JD,face++和msra待过，他的上进好学也在不断push我继续努力下去。waymo比赛的时候，我们两个实习生在ddl的最后一个周末疯狂做ensemble，虽然当时交的第一版模型就已经能够拿榜一了，但是至少我们把自己能做的都做到极致了，没有留下什么遗憾吧，结果也非常令人满意，超了第二名4.2个点。&lt;/p&gt;

&lt;p&gt;后面的路还很长，硕士的具体课题也还不确定，但是至少我希望可以在未来做出令自己满意的成果吧！最后的最后，感谢zehao，这个一直被我拿各种bug骚扰的mentor；峰哥，当初我算法面的面试官，在我弄variance那段时间也给我提供了不少建议；naiyan（我们内部都叫他首席hhh）一直跟我们讨论各种各样的idea和解决方法。感谢图森这近一年来的培养，我会继续努力的！&lt;/p&gt;

</description>
        <pubDate>Mon, 22 Jun 2020 21:53:00 +0800</pubDate>
        <link>http://localhost:4000/posts/%E5%86%99%E5%9C%A8%E5%AE%9E%E4%B9%A0%E7%BB%93%E6%9D%9F%E4%B9%8B%E9%99%85</link>
        <guid isPermaLink="true">http://localhost:4000/posts/%E5%86%99%E5%9C%A8%E5%AE%9E%E4%B9%A0%E7%BB%93%E6%9D%9F%E4%B9%8B%E9%99%85</guid>
      </item>
    
      <item>
        <title>Label Assignment in Object Detection</title>
        <description>&lt;p&gt;在最初的Faster R-CNN做法中，我们是通过框与框之间的IoU来决定anchor的正负标签的，但是这种使用IoU一刀砍的方式来决定label未免有些粗鲁，所以后续出现各种花式的label assignment，就打算整理一下～&lt;/p&gt;

&lt;p&gt;首先说说Fast R-CNN一类，通过计算anchor与GT之间的IoU，把IoU &amp;gt; fg_thres(0.7)作为正样本，IoU &amp;lt; bg_thres(0.3)作为负样本，IoU在bg_thres ~ fg_thres(0.3 ～ 0.7)之间的认为是ignore样本，看起来还挺合理～但是不免存在如下几种问题：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;问题一：如果一个框在0.3以下那它就不能被回归到0.5以上了吗？如果它被回归到了我们还把它看作负样本，那是不是某种程度上在deteriorate模型的表现呢？&lt;/li&gt;
  &lt;li&gt;问题二：与GT IoU0.9的框 与GT IoU0.55的框，应该都给1吗？他们其实是有好坏之分的，但是在使用IoU一刀砍的环境下，没法体现出来这种优劣之分。&lt;/li&gt;
  &lt;li&gt;问题三：由于我们的anchor设置是predefine的，那么可能无法保证每一个GT都存在很好的anchor和它匹配，这样就会造成一个问题：每个GT与他周围的anchor的IoU的重叠分布是不同的，这样如果我们一刀切就会导致不同GT样本被分配到的anchor不均衡。虽然现在的实现里我们会保证找到和GT匹配度最高的anchor（无论它与该GT的IoU是多少）设为正样本，但是依然没有从本质上解决这个问题。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对于问题一，我目前看到了两篇文章其实想解决这个问题，一个是HAMBox，一个是Learning from noisy labels for one stage object detection。&lt;/p&gt;

&lt;h3 id=&quot;topk&quot;&gt;TopK&lt;/h3&gt;

&lt;p&gt;首先说一下TopK吧，是我在实习的时候学到的一种方法，据说是当年fpp拿冠军的时候分享的方法，即在assign anchor label的时候，对于每个GT，我们都找到topk的样本把他们当成正样本，这样做的好处也很明显：对于小物体GT，可能和它匹配的anchor很少，这个时候如果还根据IoU来找正样本的anchor，那么可能打物体被分配了很多anchor来训练，而小物体被assign到的anchor数就比较少（突然发现可以从data imbalance的角度来看这个问题hhh），这种方法可以看作通过一种dynamic的方式来动态改变IoU阈值来划分正负样本～同时我们保证了不同大小的物体都能够得到一定的anchor进行训练。topk方法可以看作是对问题一的解决方法。&lt;/p&gt;

&lt;h3 id=&quot;learning-from-noisy-anchor&quot;&gt;Learning from Noisy Anchor&lt;/h3&gt;

&lt;p&gt;那么问题二该怎么办呢？一个很直观的想法：那我能不能根据回归出来的结果来动态的决定我的anchor的质量好坏呢？如果我能给他回归的很好，那这个anchor的确很棒，如果我回归的不是很行，那就让这个anchor爬。Learning from noisy anchor for one stage object detection干的就是这么一件事情～这篇文章的出发点就是从问题一出发的，不过是从另外一个角度来思考问题一：就是我们看作是正样本的那些anchor，是不是都很棒呢？是不是也有不是很好的样本嘞？那么怎么决定一个anchor是不是noisy的呢？作者提出了可以从回归后和GT的IoU以及分类的score来看，于是乎，这两个值乘起来，就作为我评价anchor质量的评判标准啦（文中叫做cleanliness）～所以这个anchor的质量怎么反应到我的网络中呢？首先作者把它作为cls的label放到了focal loss里面，也就是不再用0/1作label，而是使用这个cleanliness作为label，同时它还参与到regression的部分，作为权重加权回归，也就是好的anchor我们就多回归，noisy的anchor我们就少回归～所以说这篇文章实际上是从学习的过程中动态的决定anchor的label，根据网络学习的结果来决定这个anchor是好的还是坏的。感觉还是挺合理哈～&lt;/p&gt;

&lt;p&gt;8⃣️过，这篇文章其实都是把重点放在了刚开始就positive的anchor，而negative的anchor永世不可超生，也就是依然没法解决我们问题一中提到的问题。&lt;/p&gt;

&lt;h3 id=&quot;hambox&quot;&gt;HAMBox&lt;/h3&gt;

&lt;p&gt;接着就可以说一下HAMBox了～这篇文章是在人脸检测上做的，文章里说在他们的model里，anchor是没有ignore区间的，低于0.35的就都是负样本，高于0.35的就都是正样本，不过我没有怎么读过人脸检测的文章，不知道这种做法是不是common practice，但是这样assign的话，我们之前提到的问题一就更加显著，即一旦有一个anchor低于0.3的IoU，它就是负样本，我分类的时候就要抑制它，这样可能会deteriorate模型的分类能力。&lt;/p&gt;

&lt;p&gt;而HAMBox发现，最终回归出来的IoU大于0.5的检测框里，有很大的比例来自于这些刚开始的anchor与GT的IoU低于0.35的anchor。那岂不是错杀了一大批anchor？所以HAMBox提出了一种anchor补偿的策略，本质上是在训练的过程中，动态的修改那些被回归好的样本。所以HAMBox主要解决的就是我们说的问题一的问题，我会在训练的过程中，动态的把那些本身和GT重叠度不高但是最后回归的好的anchor设为正样本。具体的做法其实和topk有点类似，作者会在训练的过程中，对每个GT动态的补偿到k个anchor，也就是说，HAMBox不是像topk那样直接把所有topk都看成正样本（不过topk好像fpp也没有发paper，具体怎么做的我也不知道🤷‍♂️），而是根据回归的好坏把某些模型能够回归出来的anchor设为正样本。其实你可以看作 HAMBox的重点在于如何处理刚开始被assign为负的样本，而Learning from noisy anchor看作如何处理刚开始被assign为正的样本～&lt;/p&gt;

&lt;h3 id=&quot;atss&quot;&gt;ATSS&lt;/h3&gt;

&lt;p&gt;ATSS虽然同样在解决正负标签assign的问题，但是入手的角度是从anchor based和anchor free的区别出发。文章从RetinaNet和FCOS出发，把FCOS上的结构都在RetinaNet上加了一遍，同时对比了classification和regression分支两者的区别，最后发现RetinaNet和FCOS的区别在于：正负样本Assign的规则导致了最终点数上的差距。也就是label assignment的问题。（当然ATSS在一步一步分析这两者区别的过程也是这篇文章很棒的一部分，可以看到思路非常清晰的，不愧是shifeng大佬orz）至于ATSS的做法其实是从统计意义上来思考正负样本的定义。直观的理解就是，如果你把每个GT周围的anchor与它的IoU统计一下，其实是可以形成一个分布的，那么我通过取这个分布上的某个分位数来决定每个GT的IoU Thres岂不是很合理？其实如果再想想你可以发现ATSS也和topk有着异曲同工之妙，他们都是从每个GT出发，去argmax GT周围的的anchor，而不是 argmax proposal周围的GT。可能从GT出发来决定anchor的正负才是更为合理的方式？&lt;/p&gt;

&lt;p&gt;写到这里差不多就结束了，最后回过头来看，目前的几种解决label assignment的方式可以归纳为两种：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;动态的根据回归后的结果决定anchor的好坏&lt;/li&gt;
  &lt;li&gt;从每个GT出发assign label，而不是从anchor出发&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;[1] HAMBox: Delving into Online High-quality Anchors Mining for Detecting Outer Faces, Yang Liu, et.al&lt;/p&gt;

&lt;p&gt;[2] Bridging the Gap Between Anchor-based and Anchor-free Detection via Adaptive Training Sample Selection, Shifeng Zhang, et.al&lt;/p&gt;

&lt;p&gt;[3] Learning from Noisy Anchors for One-stage Object Detection, Hengduo Li, et.al&lt;/p&gt;

</description>
        <pubDate>Fri, 24 Apr 2020 18:32:00 +0800</pubDate>
        <link>http://localhost:4000/posts/label-assignment-in-object-detection</link>
        <guid isPermaLink="true">http://localhost:4000/posts/label-assignment-in-object-detection</guid>
      </item>
    
      <item>
        <title>Object Detection Paper Reading</title>
        <description>&lt;p&gt;目录：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Bridging the Gap between Anchor-based and Anchor-free Detection via Adaptive Training Sample Selection&lt;/li&gt;
  &lt;li&gt;Shape-aware Feature Extraction for Instance Segmentation&lt;/li&gt;
  &lt;li&gt;Region Proposal by Guided Anchoring&lt;/li&gt;
  &lt;li&gt;Feature Selective Anchor-Free Module for Single-Shot Object Detection&lt;/li&gt;
  &lt;li&gt;RDSNet: A New Deep Architecture for Reciprocal Object Detection and Instance Segmentation&lt;/li&gt;
  &lt;li&gt;Revisiting Feature Alignment for One-stage Object Detection&lt;/li&gt;
  &lt;li&gt;RepPoints: Point Set Representation for Object Detection&lt;/li&gt;
  &lt;li&gt;Is Sampling Heuristics Necessary in Training Deep Object Detectors?&lt;/li&gt;
  &lt;li&gt;Multiple Anchor Learning for Visual Object Detection&lt;/li&gt;
  &lt;li&gt;Learning from Noisy Anchors for One-Stage Object Detection&lt;/li&gt;
  &lt;li&gt;Gaussian YOLOv3: An Accurate and Fast Object Detector Using Localization Uncertainty for Autonomous Driving&lt;/li&gt;
  &lt;li&gt;Bounding Box Regression with Uncertainty for Accurate Object Detection&lt;/li&gt;
  &lt;li&gt;HAMBox: Delving into Online High-quality Anchors Mining for Detecting Outer Faces&lt;/li&gt;
  &lt;li&gt;Revisiting the Sibling Head in Object Detector&lt;/li&gt;
  &lt;li&gt;Rethinking Classifcation and Localization for Object Detection&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;bridging-the-gap-between-anchor-based-and-anchor-free-detection-via-adaptive-training-sample-selection&quot;&gt;Bridging the Gap between Anchor-based and Anchor-free Detection via Adaptive Training Sample Selection&lt;/h2&gt;

&lt;p&gt;这篇文章主要argue的一个点就是其实anchor-based和anchor-free本质上是没啥区别的，当然有一个前提条件，就是how to define positive and negative training samples。&lt;/p&gt;

&lt;p&gt;这篇文章给了一个实验，也就是RetinaNet和FCOS的先导试验，就是它先把FCOS上的东西基本上都加到RetinaNet上，结果从32.5涨到了37.0。然后现在的RetinaNet和FCOS只有两个区别，一个是如何生成训练样本，一个是是否predefine anchor。然后当作者把RetinaNet的sampling methods从IoU-based改成Spatial and scale constraints后，FCOS和RetinaNet的表现结果一致了。这就表明其实有没有anchor是不重要的，你从点开始回归还是从框回归，最后并不影响。我觉得这个点发现的挺有意思的。&lt;/p&gt;

&lt;p&gt;然后就是作者提出的ATSS了，具体想法就是先找到所有level的possible candidates的positive，然后计算他们与GT的IOU，接着计算mean和var得到对应IoU threshold。最后select对应满足条件的anchor。结果还是挺感人的，retina涨了2个点左右，FCOS涨了一个点多。&lt;/p&gt;

&lt;p&gt;最后discussion的时候作者还提到一点，就是每个点有几个anchor在用ATSS的时候并不重要，但是在用IoU的时候还是很重要的。至于原因我觉得可能是IoU定义sample的时候真的就只有IoU作为标准，所以此时多几个准的框会好很多，但是ATSS的时候，是用center来定义的，所以对于同样的center，你出几个anchor结果都是一样的。&lt;/p&gt;

&lt;h2 id=&quot;shape-aware-feature-extraction-for-instance-segmentation&quot;&gt;Shape-aware Feature Extraction for Instance Segmentation&lt;/h2&gt;

&lt;p&gt;个人感觉出发点很好的一篇文章，可惜做法实在太水了。。。&lt;/p&gt;

&lt;p&gt;其实本质上算是 segmentation-based ROIAlign，因为很多时候我们align feature的时候，因为物体畸形很多地方的feature是无效甚至会 deteriorates后面的分类和regression效果，文中举了一只猫和一只狗在一起的例子，普通的ROI Align把他们两都分成了猫（还是狗）。所以作者觉得在ROIAlign的时候如果能够知道segmentation同时进行ROIAlign，效果肯定会变好（废话）。所以作者的做法真的就是把segmentation的prediction合并到ROIAlign时候的feature map上了… 真xx简单….当然因为我们第一次ROIAlign的时候是没有segmentation的，所以作者说那我们可以像Cascade一样再来一个refine module，把第一次生成的segmentation接给第二次reg和seg的feature map，然后万事大吉。最后结果提了1.5个点左右吧，然后 casscade本来就会再涨0.5个点，所以最后也就1个点…&lt;/p&gt;

&lt;p&gt;但是讲道理，那个intuition还是挺好的…&lt;/p&gt;

&lt;h2 id=&quot;region-proposal-by-guided-anchoring&quot;&gt;Region Proposal by Guided Anchoring&lt;/h2&gt;

&lt;p&gt;之前看过一篇Cascade RPN，是将cascade的思想从RCNN放到了RPN中，通过两次iterative的预测RPN的regression，从而得到更好的proposal。这篇GA-RPN实际上是比Cascade RPN更早的一篇文章，主要思想其实也是十分直观的的，首先预测出可能出anchor的点，也就是物体的中心，这部分实际上跟FCOS的centerness有点相似，但是使用这个centerness的方法不一样吧…然后再根据可能出anchor的点预测它的h和w。当然直接预测形状实际上是不合理的，因为他们用的都是同一个CNN得到的feature，而这个时候每个点的感受野都是一样的，为啥能够预测出来不同的anchor的shape呢？所以作者提出了一个&lt;strong&gt;Feature Adaption&lt;/strong&gt;模块，用来根据得到的anchor shape接一个1x1的conv得到offset然后重新过一遍deformable的卷积，这使得得到的proposal考虑到了anchor的shape，也就是feature和anchor的consistancy（feature的形状要和anchor的形状一致）。这里陈恺dalao提到了设计anchor的两条准则，一是alignment，即anchor的中心应该与feature的中心对齐，其次是consistency，即anchor的shape与feature的shape也要对齐。其实这点一直是one stage算法的问题，即one stage一直会存在misalign的问题，因为每个点出的proposal必然会离开生成的proposal，从而降低了生成的proposal的质量。而FCOS之所以使用centerness也是因为只在centerness出anchor避免了feature misalignment的问题。&lt;/p&gt;

&lt;h2 id=&quot;feature-selective-anchor-free-module-for-single-shot-object-detection&quot;&gt;Feature Selective Anchor-Free Module for Single-Shot Object Detection&lt;/h2&gt;

&lt;p&gt;首席在一次paper reading让我看的一篇文章，打算最近把anchor free的文章都看一遍，看看能不能对这个方向有点自己的见解。很久很久之前在上Ng的课的时候他就说one-stage会是未来，那个时候我也不懂object detection是个啥，现在想想one-stage的确有超过two-stage的势头，从FCOS到之前那篇ATSS，现在大家都开始在思考two stage的这个宝贝anchor到底有没有必要。FCOS的centerness的确是个好东西，我觉得它从另外一个角度避免了feature misalignment的问题，而并非像two stage通过ROI Align来解决。但是它的感受野依然是一个局限，因为FCOS每个点的感受野，或者说feature的大小都一样，那么为啥有的点可以出大proposal，有的点可以出小propsoal呢？这个就是之前GA-RPN中提到的consisitency的问题。突然想到TridentNet里面用不同的dialated ratio来解决不同size的object检测问题。那么能不能在one-stage中也糅合Tridentnet的思想呢？话说TridentNet还是我刚来的时候看的，待会重新去看看，看看能不能有啥想法。&lt;/p&gt;

&lt;p&gt;好了，上面都是废话，现在说一下这篇文章。其实就是点出框，然后回归点到边框的距离。但是实际上这个做法是有挺多问题的，首先是有效范围，FSAF中没有centerness来指导框的回归和分类，所以作者自己定义了只在0.2原始框大小的范围内进行梯度回传，这其实就是在一定程度上避免回归出较远的框。其次由于丢失了anchor这个东西，所以对于instance分配在FPN的哪一个level上就是一个问题，原来大家都是用IoU来进行instance分配到哪个level上的，现在没有了anchor自然就没有办法计算IoU了，那怎么分配呢？作者提出了在FPN上用loss来决定。也即如果容易在那个level回归的话，那么loss肯定比其他level小，那么我们就回传loss比较小的那个分支的loss。&lt;strong&gt;不过有一个问题我一直没有搞清楚，就是对于不同level的回归target肯定不一样啊，高level的target肯定要比低level的target要小？那么loss相对来说应该从一开始就低一点？那这样不是所有的都跑去回归高level的target了？还是说都是project到原来size去算loss的？其实我觉得这个选择与初始化有关，应该一开始大家都train，train到后面选择loss最小的那个分支继续训练～&lt;/strong&gt; 所以感觉应该还是理解有所偏差，所以之后估计还要自己看看或者问问别人…&lt;/p&gt;

&lt;h2 id=&quot;rdsnet-a-new-deep-architecture-for-reciprocal-object-detection-and-instance-segmentation&quot;&gt;RDSNet: A New Deep Architecture for Reciprocal Object Detection and Instance Segmentation&lt;/h2&gt;

&lt;p&gt;也是出发点很reasonable的一篇文章，考虑的是bbox的regression其实是不合理的，用l1回归这个框不是最直接的方式，因为框本身是根据mask定义出来的，所以reg和cls分支应该结合起来。但是之前像cascade/HTC虽然探索了这部分的问题，但是计算量相当大，本文则是以一种相对较小的开销达到了比较好的效果。&lt;/p&gt;

&lt;p&gt;其实结构还是挺好懂的，但是那个metric learning的图画的我看懵了，重读了好几遍才算理清楚…理清楚后发现想法真的很直接，如果你有这个intuition，你也会选择这样做…&lt;/p&gt;

&lt;p&gt;首先作者将FPN的object stream和pixel stream给分开了，两边单独管理object和mask。那么这两者如何交流呢？就有了第一个Instance-agnositc to Instance-aware module。主要就是，object分支还多出一个2k x d的representation。干嘛呢？用来做卷积核，来卷pixel stream的图，对于每一个object都卷一次，这样就能train出每一个object的mask了。所以作者认为这是把object level的信息给了mask…emmm 勉强吧 谁知道你object多出的是个啥…然后再根据object level出的框来裁剪我们的mask。为啥要裁呢？不然你train的时候那么大一片区域结果只有那么一小块有效面积，就很难被train好，所以作者就想用bbox出的框把想要的框给裁出来单独训练。但是你一开始的框可能不那么准，所以我们多裁不如少裁，顺便还能带点noisy增加分割的鲁棒性。。。但是我觉得这步真的有点挫…名字起的倒挺好听的，叫from translation-invariant to translation-variant。然后最后一步是通过已有的mask获得新的bbox，即Mask assisted Object Detection模块。然后作者发现直接根据mask来重新裁出bbox效果并不好，尤其是在小物体上表现很差。所以作者把这个问题转化为用贝叶斯来搞，即&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(X=i|M') = \frac{P(X=i)P(M'|X=i)}{\sum_{t=1}^{w}P(X=t)P(M'|X=t)}&lt;/script&gt;

&lt;p&gt;这里的$M$就是之前的mask logits，然后作者用一个discrete Gaussian distribution来近似 $ P(X=i)$ , 然后用一个2s+1的卷积核来预测  $ P(m^x_{i-s,…i+s}\vert X=i) $ ，从而保证端到端的训练。&lt;/p&gt;

&lt;p&gt;最后的结果也还可以，因为本身这个问题我估计就不是太大。但是我觉得做的还是不够优雅，虽然的确做到了我们想要做的东西…不过我觉得应该还能找到更好的方法来做这个问题，以至于我一直觉得AdaptIS是非常优雅的，可惜单纯的segmentation想要达到好的instance level还是有点难呀~&lt;/p&gt;

&lt;h2 id=&quot;revisiting-feature-alignment-for-one-stage-object-detection&quot;&gt;Revisiting Feature Alignment for One-stage Object Detection&lt;/h2&gt;

&lt;h2&gt;&amp;amp;&amp;amp;&lt;/h2&gt;

&lt;h2 id=&quot;reppoints-point-set-representation-for-object-detection&quot;&gt;RepPoints: Point Set Representation for Object Detection&lt;/h2&gt;

&lt;p&gt;两篇放在一起写吧，都是今天看的。之所以一起写是因为两篇的实现非常相似，虽然出发点不同，但是实际上最后结构都差不多，除了一个用点一个用的box，但是最后都变成了使用deformable conv。不过还是觉得知乎上RepPoint也太不友好了…毕竟我觉得AlignDet里的insight Repoint文章提都没提，一口就是一个你是我baseline比的方法，但是实际上不是结构问题，个人觉得AlignDet是从One-stage出发考虑feature alignment的问题，而Reppoints明显是在表达点比bbox好…好了个人吐槽完毕，总的说一下两篇文章。&lt;/p&gt;

&lt;p&gt;在说AlignDet之前先讲一下之前提到的Misalignment的问题，其实object detection两个问题，一个是中心点的misalign,一个是shape的misalign。中心点的misalign我觉得centerness应该解决的差不多了，不然FCOS也不会涨那么多..第二个点就是shape的misalign。什么事shape的misalign呢？就是说大物体和小物体的感受野不应该是一样的，这也是one-stage和two-stage的一个区别之一。AlignDet在文章中做了一个实验就是去掉FPN后RetinaNet疯狂掉点但是FasterRCNN只掉了1，2个点。这也体现出One-stage Detector的确需要不同的感受野。为了克服这个问题，AlignDet提出可以先出一个offset来align shape，通过Deformable Conv来进行所谓的ROIAlign，之后就是one-stage的标准步骤了。那么RepPoint呢？主要argue的点在于bbox不是最自然表现物体的方式，虽然它是最简单的，所以他们提出要用点来表示物体。怎么做呢？还是学一个offset，用9个点来表示一个物体，同时把物体的中心作为该物体的预测点。但是很巧合的是，RepPoint也是先出一次Offset之后Align再过one-stage，跟AlignDet里面的做法完全一样，所以RepPoint中的baseline（即跟bbox比）是AlignDet也的确没错啦～但是怎么说呢，我觉得他们两的确是两个出发点，但是最后得到了同样的结构…写到最后，我自己也觉得，好像没啥意思…hhh&lt;/p&gt;

&lt;h2 id=&quot;is-sampling-heuristics-necessary-in-training-deep-object-detectors&quot;&gt;Is Sampling Heuristics Necessary in Training Deep Object Detectors?&lt;/h2&gt;

&lt;p&gt;文章读起来给人一种 “啥？这就写完了？”的感觉。简单来说就是感觉，的确切入点很新颖，however，提出的方法让我觉得有些简陋哈哈哈。不过的确work了，这点是无法否认的，当初kaiming不也是改了initlization的方式让训练work的嘛，可能我只是不大适应叭。&lt;/p&gt;

&lt;p&gt;首先作者在RetinaNet上做了一个小实验，就是去掉focal loss是否能让模型训练起来。of course not! 那么有没有啥办法呢？首先需要降低cls loss的权重，不然会出现gradient exploding。其次，作者还观察到一个点，就是background loss会突然drop，因为网络发现如果给background全预测0的时候，loss最低，所以网络会直接优化过去。怎么解决这个问题呢？作者提出通过修改initlization最后一层bias的方式。如果提高最后一层网络的bias，那么最后网络的输出就会在0.01附近，这样就可以减少网络对负样本的attention，即$ b = - log \frac{1 - \pi}{\pi}$， 取$\pi = 1e^{-5}$时取得Retina的最优mAP35.6。然后作者又提到，他发现现在整个网络预测的cls score普遍低于之前的score，所以作者降低了min_det_score到0.005，效果提升至36.4。至此，一个sampling free的object detection model训练完成。也就是说，sampling free主要靠换bias。不知道正常imbalance problem有没有人试过这种方法…我觉得是有点神奇。至于作者后面提出的几个mechanism：optimal bias initialization、guided loss、class adaptive threshold都没有给我耳目一新的感觉，尤其是后两个哈哈哈，我感觉有点拍脑袋想出来的方法。为啥呢，因为后两个也没能解释为啥这样设置，那我就算你超参叭…最后能够在cascade RCNN上提1个点，说明的确是有效的。&lt;/p&gt;

&lt;p&gt;这篇文章的确发掘出了我们平时没有注意到的问题，OHEM、focal loss的确很有效，但是没有他们真的就train不了了吗？看起来也不是这样。这也算是在imbalance problem in object detection的路上挺有意思的一次探索吧！&lt;/p&gt;

&lt;h2 id=&quot;multiple-anchor-learning-for-visual-object-detection&quot;&gt;Multiple Anchor Learning for Visual Object Detection&lt;/h2&gt;

&lt;p&gt;一篇把A放到B上work的文章，而且work的很好…比FreeAnchor还高1个点。那么它究竟是怎么work的呢？&lt;/p&gt;

&lt;p&gt;在开始之前我们需要了解什么是Multiple Instance Learning。它其实也是一种监督学习，但是和分类不同的是它的分类是不是per sample给一个label，而是一个bag给一个label。举一个🌰来说，我们要判别，一个视频中有没有出现篮球，那么如果这个视频由一万张图组成，那么如果有一张图中有出现篮球，那么这个篮球就有篮球，反之，如果1w张图中都没有出现篮球，那我们就说这个视频中没有出现篮球。所以我们训练数据的时候拿到的是1个视频和1个label（这个视频中有没有篮球）。&lt;/p&gt;

&lt;p&gt;那么这篇文章是如何把MIL用到object detection中的呢？&lt;/p&gt;

&lt;p&gt;作者首先提出现在的模型大多都没有将cls score和localization联系起来的，即cls score并不表达regression的回归效果，但是实际上我们希望能够表达，因为这样我们的NMS需要根据cls score来remove冗余的预测框。那么这就会存在可能回归出来的框很好，但是cls score较低，或者cls score很高，但是回归出来的框不是很理想，这些情况都对最后的NMS造成了负面影响。解决这个问题存在两种方法，第一种是给更好的score，也就是IoUNet想做的事情，第二种也就是作者想做的，用更适合的anchor来训练网络。当然这个说法就是FreeAnchor（作者解释是因为MLE不适合用来解非凸问题，所以FreeAnchor也不好）。那么怎么才是好的呢？作者提出了学多个anchor，每次选出top-k score的anchor用来回归，也就是从anchor bag中选若干个anchor进行训练，这样就在优化的过程中保证了给出的anchor是高score高reg，不然就不会被选到。但是这就存在一个问题，如果我每次都训练多个anchor回归一个物体，那么最后inference呢？选谁好？所以作者提出了一个selection depression optimization，是啥呢？通俗的说就是一开始会一个bag里有多个anchor，随着iter增加逐渐减少anchor，直到最后只剩一个。当然对于anchor的选择，作者还提出了另外一个方法，也就是anchor depression，好像是对anchor进行重排？这里没有看太懂…总的来说就是把MIL应用到object detection里的文章，长点还是有的，比RetinaNet涨了5个点。。。还是有点猛嗷。。。至于为啥涨，我觉得是因为第一MIL本身就work，第二给的anchor多了学习的能力增强也会带动AP上涨吧，总是看完之后没有太大感觉，倒是觉得之前自己一直想要把cls score和location解藕，我觉得如果真能把这两个东西搞成线性相关，倒是没有啥节藕的必要了吧，那应该也会接着涨点。&lt;/p&gt;

&lt;p&gt;同时刚才想到一个点，就是其实神经网络判别物体类别靠的应该是某些关键点，那么roi如果一开始坐落在某些关键点上，那么给出的cls score可能会很大，但是实际上它reg不一定准，所以可能会导致cls score和localization的mismatch。如果我们能够一定程度上解决这个问题，那应该也能涨点。&lt;/p&gt;

&lt;h2 id=&quot;learning-from-noisy-anchors-for-one-stage-object-detection&quot;&gt;Learning from Noisy Anchors for One-Stage Object Detection&lt;/h2&gt;

&lt;p&gt;这篇文章读了两遍，第一遍是在圣诞节看的，只是粗略的扫了一遍，因为之前的一些实验突然想起来这篇文章，跟zz讨论了一下label assignment的问题，就想起来这篇文章。今天跑模型的时候就抽空又把这篇文章重新读了一遍。其实很简单的一篇文章，但是形式的确挺优雅。&lt;/p&gt;

&lt;p&gt;出发点就是对于卡IoU来给anchor assign 1/0的方法实际上是不够好的，因为这样会引入noisy，因为明显GT IoU0.55和 GT IoU0.95的anchor不应该是一种anchor。那如何降低这种noisy呢？两种选择：第一种就是不用卡IoU的方式来定义anchor，第二种就是reweight学习的权重，对于有noisy的anchor就少点权重。&lt;/p&gt;

&lt;p&gt;那么怎么从这两点来解决noisy的问题呢？这篇文章首先提出了一个cleanliness score，首先它应该能够作为一种表征回归的难易或者这个anchor好坏的东西，其次应该能够作为一种reweight的参考。综合考虑这两点，作者把classification和localization两部分结合生成了cleanliness score:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;c = \alpha \cdot \text{loc_a} + (1 - \alpha) \cdot \text{cls_c}&lt;/script&gt;

&lt;p&gt;其中 loc_a 为 location accuracy, 即为与GT的IoU, cls_c为cls分支的score。这里作者提到对于每个GT只取它附近的top k计算cleanliness score。也就是其他地方的anchor的cleanliness都取0。&lt;/p&gt;

&lt;p&gt;有了cleanliness score怎么使用呢？首先把它作为一种新的label，而非0/1。那么对于RetinaNet的focal loss就可以改写为&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\text{BCE}(p, c) = -c \cdot w_p \cdot \text{log}(p) - (1-c)\cdot w_n \cdot \text{log}(1-p)&lt;/script&gt;

&lt;p&gt;这样cleanliness score实际上被作为一种soft label进入了我们的loss计算中，这在某种程度上其实是算改变了定义label的方式。其次，还需要reweight 我们每个anchor，对于noisy anchor给的权重就小一点。这个reweight的coef呗定义为&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;r = (\alpha \cdot f(\text{loc_a}) + (1-\alpha) \cdot f(\text{cls_c}))^{\gamma}&lt;/script&gt;

&lt;p&gt;然后用 $r$ 去penalize regression分支的smooth l1 loss。所以最后的形式就变成了&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_{cls} = \sum^{A_{pos}}_{i}r_i BCE(p_i, c_i) + \sum_{j}^{A_{neg}}BCE(p_j, c_j) \\
L_{reg} = \sum_{i}^{A_{pos}} r_i \text{ smooth_}l_1&lt;/script&gt;

&lt;p&gt;最后作者还做了一个实验就是cls和loc是否存在很好的联系，即对于高cls score,它与GT的IoU是不是也比较高。这样就可以保证在NMS阶段能够得到更好的效果，似乎的确是有点效果的。&lt;/p&gt;

&lt;p&gt;对于label assignment的问题，因为最近还在做Knowledge distillation的东西，所以其实teacher给出来的label是否也可以作为一种新的label定义方式呢？因为通过teacher给出的label实际上也是一种更适合学习的神经网络的对label的定义方式？&lt;/p&gt;

&lt;h2 id=&quot;gaussian-yolov3-an-accurate-and-fast-object-detector-using-localization-uncertainty-for-autonomous-driving&quot;&gt;Gaussian YOLOv3: An Accurate and Fast Object Detector Using Localization Uncertainty for Autonomous Driving&lt;/h2&gt;
&lt;h2 id=&quot;-1&quot;&gt;&amp;amp;&amp;amp;&lt;/h2&gt;
&lt;h2 id=&quot;bounding-box-regression-with-uncertainty-for-accurate-object-detection&quot;&gt;Bounding Box Regression with Uncertainty for Accurate Object Detection&lt;/h2&gt;

&lt;p&gt;两篇文章都是探究在localization阶段，也就是regression分支上如何输出网络回归的uncertainty进而作用于接下来的不论是NMS还是cocoeval scoring阶段。&lt;/p&gt;

&lt;p&gt;两篇文章都是在Regression阶段输出一个分布而非一个确定的值。前者用了Negative Log Likelihood来优化，后者用来KL Loss来优化。&lt;/p&gt;

&lt;p&gt;第一篇文章优化每个sample落在对应输出上的分布上的似然，优化函数为：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_x = - \sum^W_{i=1}\sum^H_{j=1}\sum^K_{k=1}\gamma_{ijk}\text{log}(N(x^G_{ijk}|\mu_{t_w}(x_{ijk}, \delta(x_{ijk}))+ \epsilon)&lt;/script&gt;

&lt;p&gt;其中W、H为image grid，K为每个grid的anchor数目，只有当grid上的点与某一GT的重叠度最大时，$\gamma$才为1，其他时候为0。通过优化这个NLL从而让网络学到uncertainty。最后用法也很简单，乘到score上。&lt;/p&gt;

&lt;p&gt;第二篇的思路也很直观，把GT也看作一个分布，只不过是一个var为0的Dirac delta分布。然后优化输出分布与GT分布的KL散度。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_{reg} = D_{KL}(P_D(x)|| P(x)) \\ = \frac{(x_g-x_e)^2}{2\sigma ^2} + \frac{\text{log}(\sigma^2)}{2} + \frac{\text{log}(2\pi)}{2} - H(P_D(x))&lt;/script&gt;

&lt;p&gt;由于$H(P_D(x))$是不参与求导的，所以与优化无关，最终损失函数正比于&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_{reg} \propto \frac{(x_g - x_e)^2}{2\sigma^2} + \frac{1}{2}\text{log}(\sigma^2)&lt;/script&gt;

&lt;p&gt;之后这篇文章里面还提到了Var Voting，其实算是一种集成框的形式，所以必涨点。不是我这里想提的内容，所以不讲。&lt;/p&gt;

&lt;p&gt;那么如何衡量学到的var是否真的有效呢？&lt;/p&gt;

&lt;p&gt;由于我之前一直在后面这篇文章上做些实验，干脆放上来分享一下。&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/images/paper2020_1/res152_proposal.png&quot; height=&quot;600&quot; /&gt;&lt;/center&gt;
&lt;p&gt;这张图是每条边预测的var与对应边和GT的差值的图，这里只取IoU大于0.5的作图，不然几乎看不到线性关系= = 由于我们推出来的var实际上是在学GT与预测值差值的绝对值，所以我们期望最后学出来的diff与var应该是符合线性关系，也就是应该比较均匀的分布在红线周围，但实际上模型学出来的var overestimate了，也就是说，即使diff很小，网络依然可能会预测出较大的var，这也是为啥只取了大于0.5的作图，不然scatter的点可能会覆盖整个x轴…&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/images/paper2020_1/res152_iou_proposal.png&quot; height=&quot;500&quot; /&gt;&lt;/center&gt;
&lt;p&gt;这张图是我今天看到Gaussian YoloV3那篇文章里面画的图所以想画张一样的看看效果。的确惨目忍睹啊…在低IoU的框中，网络预测出的var打了个折，那应该是咋样呢？看下别人Gaussian YoloV3里面的图就知道了…不过后来想了一下，值得注意的是，如果IoU都已经低于0.5了，那么我们还应该把这种prediction看成是与该GT匹配的框吗？同时对于IoU小于0.5的框我们是不train的，所以出现这种情况也是合理的吧&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/images/paper2020_1/gaussianyolo.png&quot; height=&quot;400&quot; /&gt;&lt;/center&gt;
&lt;p&gt;感觉KL Loss学的还是不够好啊…最近在考虑要不要试一波他这个NLL，看起来还是比KL强点…&lt;/p&gt;

&lt;h2 id=&quot;hambox-delving-into-online-high-quality-anchors-mining-for-detecting-outer-faces&quot;&gt;HAMBox: Delving into Online High-quality Anchors Mining for Detecting Outer Faces&lt;/h2&gt;

&lt;p&gt;话说好久没怎么写reading notes，不过最近看的paper感觉都没有看到啥比较有insight的paper，倒是这篇HAMBox挺有意思的，准备写一下。&lt;/p&gt;

&lt;p&gt;首先这篇文章是关于anchor label assign的，哈哈哈，是不是想到了之前看的那篇Learning from noisy labels for object detection？不过这两篇的确有着相似之处，比如说都是用anchor与GT的IoU来加权Regression分支。这点其实我之前也试过，Faster R-CNN用proposal与GT的iou加权RCNN的回归分支，好像能够在COCO涨个0.2～0.3个点左右，不过这个涨幅感觉不够大啊，倒是Davis组的那篇同时考虑了cls score与IoU融合的加权好像能涨更多。&lt;/p&gt;

&lt;p&gt;其实这篇文章主要的贡献当然不是那个focal loss for regression，实际上是说的是label assign的问题。在之前那篇文章中，作者提出用cleanliness score来加权classification分支的训练，提出了一种类似于focal loss的损失函数。这篇文章并非直接用loss入手，而是从给的数据集样本分布入手，人为加入anchor（或者更准确的说动态更新IoU阈值assign anchor的label，说到这又让我想到了ATSS 哈哈哈，ATSS是使用anchor计算分布来动态assign。啊哈，突然感觉这三篇文章都在研究一个问题！准备改天写个仔细点的文章分析一下这三个东西的共同点和区别，ATSS都是在去年12月看的了….）&lt;/p&gt;

&lt;p&gt;当然，这篇文章有几个验证实验，最有说服力的我觉得是下面两幅图&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;/images/paper2020_3/ham_iou.png&quot; width=&quot;300&quot; /&gt;&lt;/center&gt;
&lt;center&gt;&lt;img src=&quot;/images/paper2020_3/ham_anchor.png&quot; width=&quot;300&quot; /&gt;&lt;/center&gt;
&lt;p&gt;首先解释一下high quality anchors的意思是指最后通过回归结果与GT 的IoU大于0.5的anchor。那么图一的意思就是anchor小于IoU多少时，能够产生的正确检测框比例。从图中可以看到那些IoU小于0.35的anchor检测框们能够在最后产生占到89%的正确检测框。当然这张图是inference的时候，而在train的时候，这个比例也是占到了65%（训练结束时差不多70%）。可以看到实际上我们很多的正确检测框来自于我们被设置为负标签的样本。那么这么做会不会又影响呢？当然会咯，那么我们就可以看第二张图，这张图画的是真的难看懂…😒 首先解释几个词语：CPBB是corrected predicted bounding box，横坐标是每张脸（GT）match到的anchor的数目，纵坐标是被match到对应anchor数目的人脸（GT）有多少个。所以红色可以解释为，被match到对应anchor数目的脸有多少张，蓝色可以解释为被match到对应CPBB数目的人脸又多少张，绿色就是CPBB NMS之后的。那么可以发现每个人脸被assign到的anchor越多，结果也就越好，对应的蓝色就越多。然后重点来了，在NMS之后，被match到对应CPBB的人脸数目都显著下降了！为啥？如果我们NMS掉的是同样的框，那么绿色应该不会比蓝色低多少才对。真相只有一个，那就是其实我们NMS掉了之前找出来的框，但是由于分太低被remove掉了，所以就出现了大量漏检。所以说我们assign负标签给这些本来正确的样本还是有影响的哇！&lt;/p&gt;

&lt;p&gt;其实这个点发现很有意思，解决方法也不难，就是在train的过程中，动态计算每个gt周围的anchor数目label，给对应的high quality anchor重新assign label。做法的话懒得写了，其实也是根据对应阈值对每个GT找top-k个positive anchor（前提是有），这个positive anchor的定义是从最后回归的结果定义的，而非通过一开始的IoU predefined。这样就能够避免之前说到的high quality anchor被分类为negative samples的问题啦～&lt;/p&gt;

&lt;p&gt;不过说到这里，这篇文章一直说的是one stage，那么two stage是否存在这个问题呢？那RPN是不是也应该来一波这个说不定能够比Cascade RPN涨更多呢哈哈哈哈&lt;/p&gt;

&lt;h2 id=&quot;revisiting-the-sibling-head-in-object-detectortsd&quot;&gt;Revisiting the Sibling Head in Object Detector(TSD)&lt;/h2&gt;

&lt;h2 id=&quot;-2&quot;&gt;&amp;amp;&amp;amp;&lt;/h2&gt;

&lt;h2 id=&quot;rethinking-classification-and-localization-for-object-detectiondouble-head&quot;&gt;Rethinking Classification and Localization for Object Detection(Double Head)&lt;/h2&gt;

&lt;p&gt;这两篇说的都是一件事情 但是做法略微有些区别 有些殊途同归的味道&lt;/p&gt;

&lt;p&gt;首先出发点都是 回归和分类是两件事情 这两件事情需要解耦 为什么呢 因为分类注重的是 图片中的某些具有discriminative的feature，或者说全局的信息，而回归更注重边界信息，即我需要回归到哪个位置。&lt;/p&gt;

&lt;p&gt;好啦，出发点说完了，Double Head的做法可以概括为 分类two fc, 回归4conv。为什么这么说呢，还是从出发点来的，分类需要全局信息，所以用fc，它flatten了；回归需要局部信息，用conv这种局部的op。&lt;/p&gt;

&lt;p&gt;TSD的做法就比较麻烦一点，首先它有一个shared proposal，就是正常的proposal，然后这个proposal会通过不同的操作提供一个regression用的proposal和一个classfication 用的proposal。这里引入两个概念，pixel-wise offset和proposal-wise offset。pixel wise offset有点像deformable，即proposal上每个点都会有一个offset，这个offset加上原来的坐标是这个点最后取到的特征。而proposal wise offset其实就是所有点都共享一个offset，相当给定proposal xyxy去align feature的时候 把xyxy都加一个offset。然后TSD对regression head用proposal wise的offset生成新proposal，对classification head用pixel wise的offset生成proposal，然后对应head过FC就完事啦～&lt;/p&gt;

&lt;p&gt;当然除此之外，两者都提到如果保留原有的sibling head也会给结果带来一定程度上的提高。不过两个用的方式也存在区别，Double Head是把这两个head上的做ensemble，比较憨批…TSD就比较优雅，提出了Progressive constraint，有点像是consistency的东西，可能为了防止offset回归的太过火了叭，所以从loss function上限制了offset，即保证TSD Head与原有head的IoU或者cls score不能差过一定margin，不然就惩罚这个margin…不过涨点也是有的，所以也不是为了凑数搞出来的…&lt;/p&gt;

</description>
        <pubDate>Mon, 09 Dec 2019 15:27:00 +0800</pubDate>
        <link>http://localhost:4000/posts/paper-reading</link>
        <guid isPermaLink="true">http://localhost:4000/posts/paper-reading</guid>
      </item>
    
      <item>
        <title>Relearning Tabular Data Competition--Kaggle IEEE Fraud Detection</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;Content of this article&lt;/p&gt;

  &lt;ul&gt;
    &lt;li&gt;Intro&lt;/li&gt;
    &lt;li&gt;Main Section
      &lt;ul&gt;
        &lt;li&gt;Identity Clients, to find magic UID&lt;/li&gt;
        &lt;li&gt;Validation strategies&lt;/li&gt;
        &lt;li&gt;Quick visualization of feature importance&lt;/li&gt;
        &lt;li&gt;Feature Engineering
          &lt;ul&gt;
            &lt;li&gt;Feature Generation&lt;/li&gt;
            &lt;li&gt;Feature Selection – Time consistency&lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
        &lt;li&gt;Speed and Memory Optimization&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;Summary&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;/h2&gt;

&lt;p&gt;With the help of my friend Mono(actually he managed all stuffs at the last period of competition), I got my first bronze medal in Kaggle. In order to get better rankings next time, I decide to revisiting this competition and dive deeper to learn those tricks and insights behind tabular data competition. Most of them comes from kernels/ discussions published by those top  winners in this competition.&lt;/p&gt;

&lt;h2 id=&quot;main-section&quot;&gt;Main Section&lt;/h2&gt;

&lt;h3 id=&quot;identityclient-is-the-most-important-not-the-time&quot;&gt;Identity(client) is the most important, not the time&lt;/h3&gt;

&lt;p&gt;Fraud detection is actually one time series-based task since transactions varies through time. However, in this competition, time is not important since most of users with the same &lt;code class=&quot;highlighter-rouge&quot;&gt;uid&lt;/code&gt; doesn’t appear in the test dataset. So the solution is to identify those users by constructing features which identity them. And that’s why all top winners mentioned &lt;code class=&quot;highlighter-rouge&quot;&gt;uid&lt;/code&gt; in their methods sharing parts.&lt;/p&gt;

&lt;p&gt;The intuition of this idea is to manually group transactions which helps the model to identity different clients. You can refer to &lt;a href=&quot;https://www.kaggle.com/cdeotte/xgb-fraud-with-magic-0-9600#How-the-Magic-Works&quot;&gt;these figures&lt;/a&gt; to see how it works in a toy example.&lt;/p&gt;

&lt;p&gt;Actually, it can be divided into 3 steps,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Construct UID, to identify those clients. In this competition, it can be:&lt;/p&gt;

    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'day'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TransactionDT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;24&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'uid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;card1_addr1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'_'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;floor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;day&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  
&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'day'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TransactionDT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;24&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'uid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;card1_addr1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'_'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;floor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;day&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Group Aggregation Features&lt;/p&gt;

    &lt;p&gt;With the help of uids, we were able to construct new features by group aggregation features based on uids.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Remove UIDs&lt;/p&gt;

    &lt;p&gt;Since we don’t use uids in these uids to avoid overfitting.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;validation-strategies&quot;&gt;Validation Strategies&lt;/h3&gt;

&lt;p&gt;During the competition, we found that it’s quite hard to establish one reliable local CV. Local CV is extremely import when performing FE. Also, removing strongly time-related features is quite important. Here I want to note several tricks here.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Adverserial Validation&lt;/strong&gt;: Find the features have different distributions in train and test dataset. Train one model to predict the cateogory of train/test. Check the features holding the top feature importances.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Time-based Data Split&lt;/strong&gt;: Split data with the time axis, say, train the first several months skip one month and predict the last month.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;GroupKFold&lt;/strong&gt;:  The training data are the months December 2017, January 2018, February 2018, March 2018, April 2018, and May 2018. We refer to these months as 12, 13, 14, 15, 16, 17. Fold one in GroupKFold will train on months 13 thru 17 and predict month 12. Note that the only purpose of month 12 is to tell XGB when to &lt;code class=&quot;highlighter-rouge&quot;&gt;early_stop&lt;/code&gt; we don’t actual care about the backwards time predictions. The model trained on months 13 thru 17 will also predict &lt;code class=&quot;highlighter-rouge&quot;&gt;test.csv&lt;/code&gt; which is forward in time.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;quickly-visualization-your-feature-importance&quot;&gt;Quickly Visualization Your Feature Importance&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;feature_imp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;feature_importance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Value'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Feature'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;barplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Value&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Feature&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;feature_imp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;by&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Value&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ascending&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'LightGBM Features'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tight_layout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;savefig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'lgbm_importances-01.png'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;feature-engineering&quot;&gt;Feature Engineering&lt;/h3&gt;

&lt;h4 id=&quot;feature-generatation-functions-feature-encoding-functions&quot;&gt;Feature Generatation Functions (Feature Encoding Functions)&lt;/h4&gt;

&lt;p&gt;Here are some feature encoding functions. (1) &lt;code class=&quot;highlighter-rouge&quot;&gt;encode_FE&lt;/code&gt; does frequency encoding where it combines train and test first and then encodes. (2) &lt;code class=&quot;highlighter-rouge&quot;&gt;encode_LE&lt;/code&gt; is a label encoded for categorical features (3) &lt;code class=&quot;highlighter-rouge&quot;&gt;encode_AG&lt;/code&gt; makes aggregated features such as aggregated mean and std (4) &lt;code class=&quot;highlighter-rouge&quot;&gt;encode_CB&lt;/code&gt; combines two columns (5) &lt;code class=&quot;highlighter-rouge&quot;&gt;encode_AG2&lt;/code&gt; makes aggregated features where it counts how many unique values of one feature is within a group. Reference to &lt;a href=&quot;https://www.kaggle.com/cdeotte/xgb-fraud-with-magic-0-9600#Encoding-Functions&quot;&gt;Encoding Functions by cdeotte&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# FREQUENCY ENCODE TOGETHER
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;encode_FE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cols&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cols&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;vc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value_counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropna&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;normalize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;vc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'_FE'&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;', '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
&lt;span class=&quot;c1&quot;&gt;# LABEL ENCODE
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;encode_LE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;df_comb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;df_comb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df_comb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factorize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df_comb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df_comb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df_comb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df_comb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int16'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df_comb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int16'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;del&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df_comb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;', '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      
&lt;span class=&quot;c1&quot;&gt;# GROUP AGGREGATION MEAN AND STD
# https://www.kaggle.com/kyakovlev/ieee-fe-with-some-eda
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;encode_AG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main_columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aggregations&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'mean'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
              &lt;span class=&quot;n&quot;&gt;fillna&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;usena&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# AGGREGATION OF MAIN WITH UID FOR GIVEN STATISTICS
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;main_column&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;main_columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;  
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;agg_type&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aggregations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;new_col_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;main_column&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'_'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'_'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agg_type&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;temp_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;main_column&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main_column&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]])&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;usena&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temp_df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temp_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main_column&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main_column&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nan&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;temp_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temp_df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;groupby&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main_column&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agg_type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                                                        &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agg_type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_col_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;

                &lt;span class=&quot;n&quot;&gt;temp_df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temp_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;temp_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temp_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_col_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;   

                &lt;span class=&quot;n&quot;&gt;train_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_col_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temp_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;test_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_col_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temp_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                
                &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fillna&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;train_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_col_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fillna&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;test_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_col_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fillna&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                
                &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;'&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_col_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;'&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;', '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                
&lt;span class=&quot;c1&quot;&gt;# COMBINE FEATURES
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;encode_CB&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'_'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col2&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;df1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'_'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;df2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'_'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;encode_LE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;', '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
&lt;span class=&quot;c1&quot;&gt;# GROUP AGGREGATION NUNIQUE
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;encode_AG2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main_columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;main_column&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;main_columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;  
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;comb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main_column&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main_column&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]],&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;mp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;comb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;groupby&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main_column&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'nunique'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'nunique'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;train_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'_'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main_column&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'_ct'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;test_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'_'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main_column&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'_ct'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'_'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main_column&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'_ct, '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;feature-selection--time-consistancy&quot;&gt;Feature Selection – Time Consistancy&lt;/h4&gt;

&lt;p&gt;Apart from adverserial validation to find strongly time-related features, we provide another way to detect those features without time consistancy.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;One interesting trick called “time consistency” is to train a single model using a single feature (or small group of features) on the first month of train dataset and predict &lt;code class=&quot;highlighter-rouge&quot;&gt;isFraud&lt;/code&gt; for the last month of train dataset. This evaluates whether a feature by itself is consistent over time. 95% were but we found 5% of columns hurt our models. They had training AUC around 0.60 and validation AUC 0.40. In other words some features found patterns in the present that did not exist in the future.&lt;/p&gt;

  &lt;p&gt;We added 28 new feature above. We have already removed 219 V Columns from correlation analysis done &lt;a href=&quot;https://www.kaggle.com/cdeotte/eda-for-columns-v-and-id&quot;&gt;here&lt;/a&gt;. So we currently have 242 features now. We will now check each of our 242 for “time consistency”. We will build 242 models. Each model will be trained on the first month of the training data and will only use one feature. We will then predict the last month of the training data. We want both training AUC and validation AUC to be above &lt;code class=&quot;highlighter-rouge&quot;&gt;AUC = 0.5&lt;/code&gt;. It turns out that 19 features fail this test so we will remove them. Additionally we will remove 7 D columns that are mostly NAN.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;speed-and-memory-optimization&quot;&gt;Speed and Memory Optimization&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Loading data with pickle format can be faster than csv format about 60 times in this dataset.&lt;/li&gt;
  &lt;li&gt;Downcasting type for some of data to reduce your memory usage.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;I am looking forward to next tabular data competition, haha!&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;p&gt;[1] &lt;a href=&quot;https://www.kaggle.com/cdeotte/xgb-fraud-with-magic-0-9600&quot;&gt;xgb-fraud-with-magic-0-9600, kaggle kernel&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[2] &lt;a href=&quot;https://www.kaggle.com/c/ieee-fraud-detection/discussion/111510&quot;&gt;How to Find UIDs - (Unique Identification), kaggle discussion&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[3] &lt;a href=&quot;https://www.kaggle.com/c/ieee-fraud-detection/discussion/111284#latest-647701&quot;&gt;1st Place Solution - Part 1, kaggle discussion&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[4] &lt;a href=&quot;https://www.kaggle.com/c/ieee-fraud-detection/discussion/111308&quot;&gt;1st Place Solution - Part 2, kaggle discussion&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 13 Oct 2019 13:43:00 +0800</pubDate>
        <link>http://localhost:4000/posts/relearning-tabular-data-competition-kaggle-ieee-fraud-detection</link>
        <guid isPermaLink="true">http://localhost:4000/posts/relearning-tabular-data-competition-kaggle-ieee-fraud-detection</guid>
      </item>
    
      <item>
        <title>Python Parallel Programming</title>
        <description>&lt;h2 id=&quot;chapter-1-intro-to-python-and-parallel-computing&quot;&gt;Chapter 1 Intro to Python and Parallel Computing&lt;/h2&gt;

&lt;h3 id=&quot;1-computer-system-framework&quot;&gt;1. Computer system framework&lt;/h3&gt;

&lt;p&gt;SISD(I=instruction, D=data), SIMD, MISD, MIMD&lt;/p&gt;

&lt;h3 id=&quot;2-memory-management&quot;&gt;2. Memory Management&lt;/h3&gt;

&lt;p&gt;The way to get data, in other words, the time of processor to access memory data.&lt;/p&gt;

&lt;p&gt;Actually, there are two different categories:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Shared Memory&lt;/li&gt;
  &lt;li&gt;Distrbuted Memory&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;shared-memory&quot;&gt;Shared Memory&lt;/h4&gt;

&lt;p&gt;All processors share the same logic memory address.&lt;/p&gt;

&lt;p&gt;There are actually 4 ways to &lt;strong&gt;access memory&lt;/strong&gt; under shared memory framework:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;UMA(uniform memory access)&lt;/li&gt;
  &lt;li&gt;NUMA(non-uniform memory access), it can be divided into high speed memory access area and low speed memory access area. (local cache may refer to high speed)&lt;/li&gt;
  &lt;li&gt;NORMA(no remote memory access), only has local cache. To access other memory, one need to communicate with other processors.&lt;/li&gt;
  &lt;li&gt;COMA(cache only memory access)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;distributed-memory&quot;&gt;Distributed Memory&lt;/h4&gt;

&lt;p&gt;Each processor has its own physical memory and own logic memory address, they are individual.&lt;/p&gt;

&lt;p&gt;We may mention some applications of distributed memory.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;MPP(massively parallel processing)&lt;/li&gt;
  &lt;li&gt;Cluster(fail-over cluster, load balancing cluster, high-performance cluster)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Heterogeneous architecture&lt;/strong&gt;, CPU manipulates tasks and split the original work into several single and highly-parallel tasks and assigns them to GPU for high speed processing.&lt;/p&gt;

&lt;h3 id=&quot;3-parallel-programming-model&quot;&gt;3. Parallel Programming Model&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Shared Memory Model, all processors shared one memory. Computer utilizes locks and signal to control conflicts on read and write.&lt;/li&gt;
  &lt;li&gt;Multi-threading Model, one processor can have multiple tasks concurrently. Actually, this is implemented through time slice.&lt;/li&gt;
  &lt;li&gt;Message Passing Model, widely used in distributed memory system.&lt;/li&gt;
  &lt;li&gt;Data-Parallel Model, one need to specify the assignment of data and their alignment.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4-how-to-design-parallel-program&quot;&gt;4. How to design parallel program&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Tasks decomposition&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Domain Level, data may be decomposed. Maybe like the data-parallel model, IMO.&lt;/li&gt;
      &lt;li&gt;Functional Level, split the task into smaller one.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tasks Assignment&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Load balancing&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;Messaging between processors&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Polymerization&lt;/strong&gt;(聚合), in order to reduce the cost of messaging between each processor.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Mapping&lt;/strong&gt;, assign different tasks to different processors, for instance, the tasks which need to message frequently may be assigned to one processor to improve locality.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Dynamic Mapping&lt;/strong&gt;, some local mapping algorithms can be better than global ones since they can find the local optimal based on current situations.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;5-how-to-judge-the-performance-of-one-parallel-program&quot;&gt;5. How to judge the performance of one parallel program&lt;/h3&gt;

&lt;p&gt;Omitted… Refer to &lt;a href=&quot;https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/chapter1/06_How_to_evaluate_the_performance_of_a_parallel_program.html&quot;&gt;6. 如何评估并行程序的性能&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;678&quot;&gt;6,7,8&lt;/h3&gt;

&lt;p&gt;Omitted… You may refer to &lt;a href=&quot;https://www.liaoxuefeng.com/wiki/1016959663602400&quot;&gt;here(廖雪峰的python教程&lt;/a&gt;) to learn Python&lt;/p&gt;

&lt;h3 id=&quot;9-intro-to-process-and-threading&quot;&gt;9. Intro to Process and Threading&lt;/h3&gt;

&lt;p&gt;You have to remember one sentence and that’s enough:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;进程是系统进行资源分配和调度的一个独立单位. 线程是进程的一个实体,是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;chapter-2-parallel-based-on-threading&quot;&gt;Chapter 2 Parallel based on Threading&lt;/h2&gt;

&lt;p&gt;考虑到Python目前我需要用到的加速都是基于进程的，打算跳过这章，先学第三章，以后有空再回来学这章。至于为啥嘞，首先Python有GIL，所以不论你开几个线程，默认Python都只会占用一个核，可是我们现在基本上都是多核处理器了，所以想要提高效率就要增加每个CPU的使用率。其次，线程相对于进程的一个比较大的优势就是它的上下文切换速度比进程快，但是实际上利用多个CPU并行的提升远远大于上下文切换的代价~没错 我就是这么功利：）&lt;/p&gt;

&lt;h2 id=&quot;chapter-3-parallel-based-on-process&quot;&gt;Chapter 3 Parallel based on Process&lt;/h2&gt;

&lt;h3 id=&quot;1-intro&quot;&gt;1. Intro&lt;/h3&gt;

&lt;p&gt;In this chapter, we will mainly cover about &lt;code class=&quot;highlighter-rouge&quot;&gt;multiprocessing&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;mp4py&lt;/code&gt; module in Python library.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;multiprocessing&lt;/code&gt; implements the shared memory mechanism which enables processors to access shared memory.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mp4py&lt;/code&gt; implements message passing mechanism (design pattern) which enables processes messages without sharing anything. All information are passed through messages.&lt;/p&gt;

&lt;p&gt;Here is one example code&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;multiprocessing&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pool&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The author(maybe translator) mentioned that function f should be declared out of this file and called as one module. However, that’s not necessary. What you need to do is to define function &lt;code class=&quot;highlighter-rouge&quot;&gt;f&lt;/code&gt; before you declare process pool, like what I wrote above.&lt;/p&gt;

&lt;h3 id=&quot;2-how-to-generate-one-process&quot;&gt;2. How to generate one process?&lt;/h3&gt;

&lt;p&gt;Spawn means generate, which refers to the generation of son process by its father process. These process can be executed asynchronous or synchronous. The following code shows how can we create processes:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;multiprocessing&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;foo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;called function in process: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'__main__'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;process_jobs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multiprocessing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Process&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;foo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;process_jobs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;start&lt;/code&gt; means start this process and &lt;code class=&quot;highlighter-rouge&quot;&gt;join&lt;/code&gt; means wait until the process finished.&lt;/p&gt;

&lt;p&gt;If you forget to call &lt;code class=&quot;highlighter-rouge&quot;&gt;join&lt;/code&gt; method, the process will not be freed, even if the main process ends.&lt;/p&gt;

&lt;h3 id=&quot;3-how-to-name-one-process&quot;&gt;3. How to name one process&lt;/h3&gt;

&lt;p&gt;Omitted… No use for now&lt;/p&gt;

&lt;h3 id=&quot;4-how-to-run-process-in-the-background&quot;&gt;4. How to run process in the background&lt;/h3&gt;

&lt;p&gt;Set the &lt;strong&gt;daemon&lt;/strong&gt; to be True.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;multiprocessing&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;foo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multiprocessing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;current_process&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Starting&amp;gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Exiting &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'__main__'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;bg_process&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multiprocessing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Process&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'bg_process'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;foo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;bg_process&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;daemon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;NO_bg_process&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multiprocessing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Process&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'NO_bg_process'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;foo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;NO_bg_process&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;daemon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;bg_process&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;NO_bg_process&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;background process is not allowed to new more son process. Otherwise, its child process may become orphan process when background process exit along with its father process.&lt;/p&gt;

&lt;h3 id=&quot;5-how-to-terminate-process&quot;&gt;5. How to terminate process&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;multiprocessing&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;foo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Starting function'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Finished function'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'__main__'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multiprocessing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Process&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;foo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;terminate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;7-how-to-exchange-object-within-processes&quot;&gt;7. How to exchange object within processes&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;multiprocessing&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;random&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Producer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiprocessing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Process&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;queue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;queue&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;queue&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;queue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Process Producer : item &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;d appended to queue &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;The size of queue is &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;queue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;qsize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Consumer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiprocessing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Process&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;queue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;multiprocessing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Process&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;queue&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;queue&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;queue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;the queue is empty&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;queue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Process Consumer : item &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;d popped from by &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'__main__'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;queue&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multiprocessing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Queue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;process_producer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Producer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;queue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;process_consumer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Consumer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;queue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;process_producer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;process_consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;process_producer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;process_consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;8-how-to-synchronize-processes&quot;&gt;8. How to synchronize processes&lt;/h3&gt;

&lt;p&gt;When sharing data among processes, one need to take the responsibility to garentee that data is consistant. Here are some tips:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Lock, for each &lt;code class=&quot;highlighter-rouge&quot;&gt;Lock&lt;/code&gt; class, it holds two methods: &lt;code class=&quot;highlighter-rouge&quot;&gt;acquire()&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;release()&lt;/code&gt; to control the rights to read/write.&lt;/li&gt;
  &lt;li&gt;Event, to implement simple messages between processes. One process sends the signal and the other waits the signal. (&lt;code class=&quot;highlighter-rouge&quot;&gt;set()&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;clear()&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;Condition, &lt;code class=&quot;highlighter-rouge&quot;&gt;wait()&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;notify_all()&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Semaphore&lt;/li&gt;
  &lt;li&gt;Rlock&lt;/li&gt;
  &lt;li&gt;Barrier, to limit the processing order of processes&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Here is an example on how to utilize &lt;code class=&quot;highlighter-rouge&quot;&gt;barrier&lt;/code&gt; to synchronize two processes.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;multiprocessing&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;multiprocessing&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Barrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Lock&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Process&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;datetime&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datetime&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;test_with_barrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;synchronizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;serializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multiprocessing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;current_process&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;synchronizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wait&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;now&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;serializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;process &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s ---&amp;gt; &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datetime&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fromtimestamp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;now&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;test_without_barrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multiprocessing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;current_process&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;now&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;process &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s ---&amp;gt; &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datetime&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fromtimestamp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;now&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
  
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'__main__'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;synchronizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Barrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;serializer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Lock&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Process&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'p1-test_with_barrier'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_with_barrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;synchronizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;serializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Process&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'p2-test_with_barrier'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_with_barrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;synchronizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;serializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Process&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'p3-test_without_barrier'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_without_barrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Process&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'p4-test_without_barrier'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_without_barrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;9-a-simple-way-to-share-data-among-processes-manager&quot;&gt;9. A simple way to share data among processes– Manager!&lt;/h3&gt;

&lt;p&gt;When you new a manager, it can hold what you want and allows different processes to access it.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;multiprocessing&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;worker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;key = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;d value = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;d&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
  
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;__main__&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;mgr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multiprocessing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Manager&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mgr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;jobs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiprocessing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Process&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;worker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jobs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jobs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Results&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;10-how-to-use-processpool&quot;&gt;10. How to use ProcessPool&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;apply()&lt;/code&gt;: block until getting result&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;apply_async()&lt;/code&gt;: the return value is an object, and it’s a asynchronous operation, which means, the main process will continue until all child processes start processing.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;map()&lt;/code&gt;: it can receive iteratable data and process functions in parallel.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;map_async()&lt;/code&gt;: omit&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;multiprocessing&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;function_square&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'__main__'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;pool&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multiprocessing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;processes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;pool_outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;function_square&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;pool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;pool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;由于MPI4Py在mac上好像装不上，而且我可能用不到，就又跳了。。。第三章结束～&lt;/p&gt;

&lt;h2 id=&quot;chapter-4-asynchronous-programming&quot;&gt;Chapter 4 Asynchronous Programming&lt;/h2&gt;

&lt;h3 id=&quot;1-use-concurrentfutures-module&quot;&gt;1. Use &lt;code class=&quot;highlighter-rouge&quot;&gt;concurrent.futures&lt;/code&gt; Module&lt;/h3&gt;

&lt;p&gt;This module consists of:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Concurrent.futures.Executor&lt;/code&gt;, which is a virtual base class, and provides the method to execute asynchronize.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;submit(function, argument)&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;map(function, augment)&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;shutdown(Wait=True)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;concurrent.futures&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;num_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;evaluate_item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result_item&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;number&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;__main__&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;evaluate_item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
  &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;concurrent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;futures&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ThreadPoolExecutor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_workers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;executor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;futures&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;executor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;submit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;evaluate_item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;future&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;concurrent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;futures&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as_complete&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;futures&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
      
  &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;concurrent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;futures&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ProcessPoolExecutor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_workers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;executor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;futures&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;executor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;submit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;evaluate_item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;future&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;concurrent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;futures&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as_complete&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;futures&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The above code implements how to utilize &lt;code class=&quot;highlighter-rouge&quot;&gt;ThreadPoolExecutor&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;ProcessPoolExecutor&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&quot;2-use-asyncio-to-manage-events-loop&quot;&gt;2. Use &lt;code class=&quot;highlighter-rouge&quot;&gt;Asyncio&lt;/code&gt; to manage events loop&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Asyncio&lt;/code&gt; consists of&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Events Loop, so each process owns their own event loop&lt;/li&gt;
  &lt;li&gt;Coroutine(协程) is the general concepts of child process. It can be paused during processing, so that it can wait until something finished&lt;/li&gt;
  &lt;li&gt;Futures, represents for unfinished computation&lt;/li&gt;
  &lt;li&gt;Tasks, the child class of &lt;code class=&quot;highlighter-rouge&quot;&gt;Asyncio&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The first question is what is event loop?&lt;/p&gt;

&lt;p&gt;During the process of the program, it continously trace the order of events and put them into the queue.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;events&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;getEvents&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;events&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  	&lt;span class=&quot;n&quot;&gt;processEvent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here is an example code&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;asyncio&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;datetime&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;func_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Func1 called&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;call_later&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;func_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;func_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Func2 called&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;call_later&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;func_3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;func_3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Func3 called&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;call_later&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;func_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;func_4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Func4 called&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;call_later&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;func_4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;asyncio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_event_loop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;end_loop&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;9.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;call_soon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;func_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end_loop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run_forever&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;use-asyncio-to-manage-coroutines&quot;&gt;Use &lt;code class=&quot;highlighter-rouge&quot;&gt;Asyncio&lt;/code&gt; to manage Coroutines&lt;/h3&gt;

&lt;p&gt;Before we start this lesson, you need to know what is &lt;strong&gt;Coroutines&lt;/strong&gt;. Actually, coroutine is something like child function. The difference between child function and coroutine is that child function needs to be called by the main process while coroutines executed by themselves and they are connected by channels.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;asyncio&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;asyncio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coroutine&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;coroutine_func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;func_arguments&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# Do Something
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Let’s see how to simulate finite state machine through coroutines:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;asyncio&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;random&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;randint&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;asyncio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coroutine&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;StartState&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Start State called &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;input_value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;State2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;State1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Resume of the Transition : &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Start State calling &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;asyncio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coroutine&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;State1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transition_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;outputValue&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;State 1 with transition value = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transition_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;input_value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;...Evaluating...&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;State3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;State2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;State 1 calling &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputValue&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;asyncio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coroutine&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;State2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transition_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;outputValue&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;State 2 with transition value = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transition_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;input_value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;...Evaluating...&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;State1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;State3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;State 2 calling &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputValue&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;asyncio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coroutine&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;State3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transition_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;outputValue&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;State 3 with transition value = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transition_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;input_value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;...Evaluating...&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;State1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;EndState&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;State 3 calling &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputValue&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;asyncio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coroutine&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;EndState&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transition_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;outputValue&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;End state with transition value = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transition_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Stop computation...&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputValue&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;asyncio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_event_loop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run_until_complete&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;StartState&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Something like DFS actually hhh.&lt;/p&gt;

&lt;h3 id=&quot;use-asyncio-to-control-tasks&quot;&gt;Use &lt;code class=&quot;highlighter-rouge&quot;&gt;Asyncio&lt;/code&gt; to control Tasks&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;asyncio&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;asyncio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coroutine&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;factorial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Asyncio.Task: Compute factorial(&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s)&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;asyncio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Asyncio Task - factorial(&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s) = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;asyncio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coroutine&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fibonacci&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Asyncio Task: Compute Fib (&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s)&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;asyncio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Asyncio Task - fib(&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s) = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;asyncio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coroutine&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;binomialCoeff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Asyncio Task: Compute binomialCoeff (&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s)&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;asyncio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Asyncio Task - binomialCoeff(&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s, &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s) = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;tasks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;asyncio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Task&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factorial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;asyncio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Task&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fibonacci&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;asyncio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Task&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;binomialCoeff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;asyncio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_event_loop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run_until_complete&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;asyncio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wait&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tasks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So you can view this program as something that an execute line skip among three functions(actually coroutines). When we called &lt;code class=&quot;highlighter-rouge&quot;&gt;yield&lt;/code&gt;, we will move to the next task.&lt;/p&gt;

&lt;p&gt;And if you don’t call &lt;code class=&quot;highlighter-rouge&quot;&gt;yield&lt;/code&gt;, you may find these tasks are executed one by one orderly.&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;p&gt;[1] &lt;a href=&quot;https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/index.html&quot;&gt;Python并行编程 中文版&lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Mon, 07 Oct 2019 18:39:00 +0800</pubDate>
        <link>http://localhost:4000/posts/python-parallel-programming</link>
        <guid isPermaLink="true">http://localhost:4000/posts/python-parallel-programming</guid>
      </item>
    
      <item>
        <title>RCNN series</title>
        <description>&lt;h2 id=&quot;outline&quot;&gt;Outline&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;From R-CNN to Mask RCNN&lt;/p&gt;

  &lt;ol&gt;
    &lt;li&gt;R-CNN&lt;/li&gt;
    &lt;li&gt;Fast R-CNN&lt;/li&gt;
    &lt;li&gt;Faster R-CNN&lt;/li&gt;
    &lt;li&gt;FPN&lt;/li&gt;
    &lt;li&gt;FPN + RPN + Fast R-CNN = Faster R-CNN&lt;/li&gt;
    &lt;li&gt;FPN + RPN + Fast R-CNN + Mask Prediction = Mask R-CNN&lt;/li&gt;
  &lt;/ol&gt;

  &lt;p&gt;Mask R-CNN&lt;/p&gt;

  &lt;ol&gt;
    &lt;li&gt;ROI Align
      &lt;ol&gt;
        &lt;li&gt;Bilinear interplolation&lt;/li&gt;
        &lt;li&gt;RoI pooling-&amp;gt;RoI align&lt;/li&gt;
      &lt;/ol&gt;
    &lt;/li&gt;
    &lt;li&gt;Loss Function&lt;/li&gt;
    &lt;li&gt;Application&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;from-r-cnn-to-mask-r-cnn&quot;&gt;From R-CNN to Mask R-CNN&lt;/h2&gt;

&lt;p&gt;Let’s first go through those methods on how they detect object:&lt;/p&gt;

&lt;h3 id=&quot;traditional-method&quot;&gt;Traditional method&lt;/h3&gt;

&lt;p&gt;sliding windows detector. However, brute force approach cost too much time.&lt;/p&gt;

&lt;h3 id=&quot;r-cnn&quot;&gt;R-CNN&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;../images/rcnn/rcnn.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Selective Search. Cluster them with colors/ … which have similar features. Then merge these proposals.&lt;/p&gt;

&lt;p&gt;Ideas:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Region proposal: selective search 2000 RoIs&lt;/li&gt;
  &lt;li&gt;Bounding box regression and classification&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Bounding Box&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Proposal: $P_x, P_y, P_w, P_h$&lt;/p&gt;

&lt;p&gt;Ground Truth: $G_x, G_y, G_w, G_h$&lt;/p&gt;

&lt;p&gt;Mapping: 
&lt;script type=&quot;math/tex&quot;&gt;G_x = P_w d_x(P) + P_x\\
G_y = P_h d_y(P) + P_y\\
G_w = P_w \text{exp}(d_w(P))\\
G_h = P_h \text{exp}(d_h(P))&lt;/script&gt;
The target is to learn parameters: $d_x, d_y, d_w, d_h$.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;fast-r-cnn&quot;&gt;Fast R-CNN&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Apply the region proposal method on the feature maps directly&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/rcnn/fastrcnn.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Ideas:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Region proposal from feature maps instead of input image&lt;/li&gt;
  &lt;li&gt;Warp the patches to a fixed size using ROI pooling&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Limit: Still use selective search which is time-consuming&lt;/p&gt;

&lt;h4 id=&quot;roi-pooling&quot;&gt;ROI Pooling&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;../images/rcnn/roi_pooling.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;If we want 2 x 2 max pooling, then the final size of square will not be the same.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;faster-r-cnn&quot;&gt;Faster R-CNN&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;../images/rcnn/fasterrcnn.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Replaces the region proposal method by an internal deep network&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Ideas: Get region proposals by region proposal network (FPN)&lt;/p&gt;

&lt;p&gt;Limit: Only use single scale feature map for detection&lt;/p&gt;

&lt;h4 id=&quot;rpn&quot;&gt;RPN&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;../images/rcnn/archor.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Prediction: For each location in feature maps, RPN make k guess.(k anchors).&lt;/p&gt;

&lt;p&gt;Training: which object is the anchor responsible for? According to IoU.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;fpn&quot;&gt;FPN&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Faster R-CNN is a sinle sacle object detection and may miss small objects&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/rcnn/fpn.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;a) time consuming&lt;/p&gt;

&lt;p&gt;b) faster rcnn: single scale object&lt;/p&gt;

&lt;p&gt;c) SSD&lt;/p&gt;

&lt;p&gt;d) FPN: Accurage location + High semantics&lt;/p&gt;

&lt;h4 id=&quot;resnet-fpn&quot;&gt;ResNet FPN&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;../images/rcnn/resnet_fpn.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;How to assign RoIs of different scales to the pyramid levels?&lt;/p&gt;

&lt;p&gt;$k = [k_0 + log_2(\sqrt{wh}/ 224)]$&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;mask-r-cnn&quot;&gt;Mask R-CNN&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;../images/rcnn/maskrcnn.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;FPN+RPN+Fast R-CNN+Mask Prediction = Mask R-CNN&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Backbone: ResNet-FPN&lt;/p&gt;

&lt;p&gt;Head: Bounding box regression, classification and Mask prediction&lt;/p&gt;

</description>
        <pubDate>Tue, 27 Aug 2019 11:59:00 +0800</pubDate>
        <link>http://localhost:4000/posts/rcnn-series-time</link>
        <guid isPermaLink="true">http://localhost:4000/posts/rcnn-series-time</guid>
      </item>
    
      <item>
        <title>XGBoost Explanation</title>
        <description>&lt;p&gt;In most kaggle competition, especially in tabular data ones, Gradient Boosting Machine(GBM) ha s shown its competitive performance, even surpass neural network by a large margin. Believe it or not, IEEE-CIS Fraud Detection[1] is an example. In this post, we will mainly focus on the algorithm on XGBoost and Gradient Boosting.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;intro-to-xgboost&quot;&gt;Intro to XGBoost&lt;/h2&gt;

&lt;p&gt;XGBoost[2] is the abbreviation of eXtreme Gradient Boosting. The features of XGBoost are&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Based on the boosting tree which can deal with sparse data&lt;/li&gt;
  &lt;li&gt;Weighted function for searching best split point&lt;/li&gt;
  &lt;li&gt;Parallel and distributed computation&lt;/li&gt;
  &lt;li&gt;Blocked data for high efficiency computation&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;fundamental-concepts&quot;&gt;Fundamental Concepts&lt;/h2&gt;

&lt;h3 id=&quot;optimazation-in-functional-space&quot;&gt;Optimazation in Functional Space&lt;/h3&gt;

&lt;p&gt;In supervised learning problem, our target is to learn a best assumption $F^*(x)\in H$ which have the minimum general error.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;F^*(X) = arg min_{F(X)}E_{y, X}\Psi(y, F(X))&lt;/script&gt;

&lt;p&gt;$\Psi(y, F(X))$ is some kind of loss function.&lt;/p&gt;

&lt;p&gt;since we don’t know union distribution $P(X, Y)$, we can only use mean error in training data to perform nondestructive analysis. If we choose different hypothesis, we will get different $P$, and therefore, different mean error.Then our problem will become an optimazation in a $N$ dimensional space:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;min\Psi(P) = \Psi(y, F(x_1), F(x_2), ..., F(x_N))&lt;/script&gt;

&lt;p&gt;which means, our optimization target is to minimize the expectation of loss function which specified on $y$ in the marginal distribution of $x$.&lt;/p&gt;

&lt;p&gt;If our loss function is tractable, we can use gradient-based optimization methods to find the point $P^{\star}$ in space $P$ to minimize $\Psi(P)$. At this time, the assumption is what we want for $F^{*}$.&lt;/p&gt;

&lt;h3 id=&quot;forward-stagewise-additive-modeling&quot;&gt;Forward Stagewise Additive Modeling&lt;/h3&gt;

&lt;p&gt;FSAM is the core of boosting algorithm. The main idea of ensemble method is to train multiple models and combine them together to form a competitve model. In Boosting algorithms, we often generate base learners iteratively and add them together to form the final predictor.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;F_{m-1}(x) = \sum_{k=1}^{m-1}\alpha_k f_k(x)&lt;/script&gt;

&lt;p&gt;In the next iteration, we are going to train $f_m(x)$ to learn the residual&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;(\alpha_m, f_m(x)) = \text{arg min} E_{y,X} \Psi(y, F_{m-1}(X) + \alpha f(x)) \\ F_m{x} = F_{m-1}(x)+ \alpha_m f_m(x)&lt;/script&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;gradient-boosting&quot;&gt;Gradient Boosting&lt;/h2&gt;

&lt;p&gt;When talking about search for next residual, there is a simple way in optimization theory–linear search. Suppose our loss function is first-order tractable. Then we can compute the gradient for $P_{m-1}$ with respect to loss function and get the minus gradient $\rho_{m-1}$.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\nabla \Psi(P_{m-1}) = -\frac{\partial\Psi(P_{m-1})}{\partial P_{m-1}} \\ =-\frac{\partial \Psi(F_{m-1}(X))}{\partial F_{m-1}(X)}&lt;/script&gt;

&lt;p&gt;Then search point $P_m$ which meets the minimum loss in the minus gradient direction&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P_m = \text{arg min}_{\lambda} \Psi (P_{m-1} - \lambda \nabla \Psi(P_{m-1}))\\ = F_{m-1}(X) - \lambda_m \frac{\partial \Psi (F_{m-1}(X))}{\partial F_{m-1}(X)}&lt;/script&gt;

&lt;p&gt;You may ask, why not just to learn the residual given from loss function directly?&lt;/p&gt;

&lt;p&gt;I found the answer from book &amp;lt;Statistical Learning Methods&amp;gt; by Li hang. When loss function is square error or exponantial error, the optimization will be easy. But what about other loss function format? Hence, Freidaman proposed gradient boosting method, which is the approximation of fastest descent algorithm. The core of this idea is to utilize the minus gradient at this point as the approximation of residual to learn a base tree.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;xgboost&quot;&gt;XGBoost&lt;/h2&gt;

&lt;h3 id=&quot;loss-function-for-xgboost&quot;&gt;Loss function for XGBoost&lt;/h3&gt;

&lt;p&gt;XGBoost is tree-based boosting algorithm and it optimize the original loss function and adds regularization term&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Psi (y, F(X)) = \sum_{i=1}^N \Psi(y_i, F(X_i)) + \sum_{m=0}^T \Omega(f_m) \\ =  \sum_{i=1}^N \Psi(y_i, F(X_i)) + \sum_{m=0}^T (\gamma L_m + \frac{1}{2}\lambda\lvert\lvert\omega\lvert\lvert^2)&lt;/script&gt;

&lt;p&gt;Among which $L_m$ is the number of leaves of $m^{th}$ iterative tree and $\omega$ is the output of each leave node in $f_m$.&lt;/p&gt;

&lt;p&gt;XGBoost is also an addtive model. However, instead of to fit the minus gradient at $F_{m-1}(X)$, XGBoost learns the Talyor expansion at this point with respect to loss function and minimize this loss error to train base learner.&lt;/p&gt;

&lt;p&gt;Hhh, remember the last paragraph in the previous chapter, the intuition of computing minus gradient is that the residual loss is hard to optimize. But for XGBoost, it use Talyor expansion to conquer this issue&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Psi (y, F(X)) = \sum_{i=1}^N \Psi(y_i, F_{m-1}(x_i) + f_m(x_i)) + \sum_{m=0}^T \Omega(f_m) \\ \qquad \qquad \qquad\qquad \approx \sum_{i=1}^N \Psi(y_i, F_{m-1}(X_i) + g_i f_m(x_i) + \frac{1}{2}h_i f_m^2(x_i)) + \sum_{m=0}^T \Omega(f_m)&lt;/script&gt;

&lt;p&gt;among which $g_i$ is the first-order gradient at $P_{m-1}(X)$ with respect to $F_{m-1}(x_i)$ and $h_i$ is the second-order gradient at $P_{m-1}(X)$.&lt;/p&gt;

&lt;p&gt;Since $\Psi(y_i, F_{m-1})$ is constant as for $m^{th}$ iteration, just move it outside of paranthesis&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Psi_m = A +  \sum^N_{i=1}[g_i f_m(x_i) + \frac{1}{2}h_i f_m^2(x_i)] + \Omega(f_m)&lt;/script&gt;

&lt;h3 id=&quot;convert-sample-based-loss-into-node-based&quot;&gt;Convert sample-based loss into node-based&lt;/h3&gt;

&lt;p&gt;Before writing this post, I am wondering why need us to compute the optimal output for each leave node? Just find the best split point to reach the best information gain may be ok. However, instead of using entropy gain of information, XGBoost proposes a new target function which directly optimize loss function. To make it convinent when computing the best split point when constructing trees, we need to first convert the sample-based loss function into node-based ones. If you don’t know what is sample-based and node-based, let’s see this example:&lt;/p&gt;

&lt;p&gt;Suppose at iteration $m$, we’ve construct one tree which has $L$ leave nodes($l_1, l_2, …, l_L$), and assume that $I_j = (i\lvert q(x_i) = j)$ represents that the index of samples which are assigned to the  $j^{th}$ leave node, and $q$ denotes the result from the $m^{th}$ tree. Then we can convert the original sample-based loss function into node-based one. Please check the iterative symbol of sum function.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{\Psi}_m = \sum_{i=1}^N[g_i f_m(x_i) + \frac{1}{2}h_i f_m^2(x_i))] \\ \qquad \qquad \qquad = \sum_{j=1}^L[(\sum_{i\in I_j}g_i)\omega_j + \frac{1}{2}(\lambda + \sum_{i\in I_j}h_i)\omega^2_j] + \gamma L&lt;/script&gt;

&lt;p&gt;Then, for each leave node, we can rewrite the function to make it simpler:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{\Psi} = \sum_{j=1}^L f(\omega_j) + \gamma L&lt;/script&gt;

&lt;p&gt;where $f(\omega_j) = (\sum_{i\in I_j} \omega_j) + \frac{1}{2}(\lambda + \sum_{i\in I_j}h_i)\omega^2_j$&lt;/p&gt;

&lt;p&gt;Now, we just need to compute leave node to get the optimal solution. Further, however can we find the optimal solution given these leave node parameters? An intuitive way is to use gradient based search: let its gradient equal to zero:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\omega^{\star} = -\frac{\sum_{i\in I_j}g_j}{\lambda + \sum_{i\in I_j}h_j}&lt;/script&gt;

&lt;p&gt;Until here, let’s compute the expected minimum loss function here:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{\Psi}_m(q) = -\frac{1}{2}\sum_{j=1}^L \frac{G_j^2}{\lambda + H_j} + \gamma L&lt;/script&gt;

&lt;p&gt;where $G_j = \sum_{i\in I_j}g_j$ and $H_j = \sum_{i\in I_j}h_j $.&lt;/p&gt;

&lt;p&gt;So here we are. Instead of iterate each samples, we just need to iterate leave nodes to compute the target loss function.&lt;/p&gt;

&lt;h3 id=&quot;split-condition&quot;&gt;Split Condition&lt;/h3&gt;

&lt;p&gt;Similar to GBDT, XGBoost here compute the decreasement of loss function before and after the split.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Delta\Psi = \frac{1}{2}[\frac{G_L^2}{\lambda + H_L} + \frac{G_R^2}{\lambda + H_R} - \frac{G^2}{\lambda + H}] -\gamma&lt;/script&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;In this post, we’ve went through the whole process of XGBoost as well as something related to gradient boosting. However, there do exists something that we didn’t cover, espeically about split methods and how to boost the speed of search. I decided to discuss these topic in next post, about LightGBM which advanced XGBoost with faster speed. And its core idea is to optimize the search phase.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;p&gt;[1] &lt;a href=&quot;https://www.kaggle.com/c/ieee-fraud-detection/&quot;&gt;IEEE-CIS Fraud Detection- A kaggle Competition&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[2] &lt;a href=&quot;&quot;&gt;XGBoost: A Scalable Tree Boosting System&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 13 Aug 2019 13:09:00 +0800</pubDate>
        <link>http://localhost:4000/posts/xgboost-explanation</link>
        <guid isPermaLink="true">http://localhost:4000/posts/xgboost-explanation</guid>
      </item>
    
      <item>
        <title>Gradient Boosting Decision Tree Explanation</title>
        <description>&lt;p&gt;GBDT(Gradient Boosting Decision Tree) is a kind of iterative algorithm. It consists of multiple decision tree, and the result is derived from these trees. In this post, we will cover the following parts from intuitive way, in other words, not so mathematical :)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Decision Tree(Regression DT and Classification DT)&lt;/li&gt;
  &lt;li&gt;Bagging and Boosting&lt;/li&gt;
  &lt;li&gt;An Example of GBDT&lt;/li&gt;
  &lt;li&gt;Difference between GBDT and Adaboost&lt;/li&gt;
  &lt;li&gt;Shrinkage&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;decision-tree&quot;&gt;Decision Tree&lt;/h2&gt;

&lt;p&gt;When it comes to decision tree, most people may think about C45 classification tree. However, GBDT doesn’t use classification DT as its base tree, but the regression decision tree. The reason of this is that GBDT is to learn the residual of the prediction, and probably CDT can not learn such a uncertainty value which enables us to sum it up. So what’s the difference between CDT and RDT?&lt;/p&gt;

&lt;p&gt;For CDT, it iteratively choose different threshold for each feature, and find the one which yields the best improvement for entropy(maximize entropy here can be understood as let each node only holds one kind of instance). In most cases, we may not let every node holds only one kind instance, hence early stopping is introduced (For example the node can not be divided because it must hold at least $n$ instances).&lt;/p&gt;

&lt;p&gt;The process of RDT is similar to CDT, however, for each node we can compute the prediction value. Take Age prediction as example, the prediction value is equal to the average of all instances which are assigned to this node. What’s more, the judge value/ objecitve function is not the entropy but the prediciton error.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;bagging-and-boosting&quot;&gt;Bagging and Boosting&lt;/h2&gt;

&lt;p&gt;Bagging and boosting are probably the most important topics in ensemble methods. Random forests is the representation of bagging. The main intuition is to randomly select samples from dataset and train your model. When obtaining plentiy of models, just average them up and you will get your answer (Ok, this is not the formal definition of Bagging, actually, it is a part of how random forests works). In view of our topic is GBDT, I won’t spend much ink on Bagging. So what’s boosting? Boosting is also utilizing multiple base learner to predict but totally different. The base learner inside GBDT is not to learn the final prediction value but the residual value of the previous base learners. Take age prediction as example, say A’s true age is 16. If the first base learner predict A’s age is 10 then the second learner is to learn the residual value of true age and the previous prediction value (16 - 10 = 6).&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;example-of-gbdt&quot;&gt;Example of GBDT&lt;/h2&gt;

&lt;p&gt;Let’s take age prediction as an example, yeah, I love this example. Say we have 4 people A,B,C,D and their ages 14, 16, 24, 26. If we choose a DT to predict the age, the result may probably looks like this:&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/images/gbdt/dt.png&quot; height=&quot;300&quot; /&gt;&lt;/center&gt;
&lt;center&gt;&lt;i&gt;An illustraction of an decision tree.&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;Then we utilize GBDT to learn this task, and we limit the maximum number of nodes is 2, and n_estimators=2, then we may get this figure.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/images/gbdt/gbdt.png&quot; /&gt;&lt;/center&gt;
&lt;center&gt;&lt;i&gt;An illustraction of an GBDT.&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;Note that in the second tree, it not learn the value of 14, 16, 24, 26 but the residual value from the previous base learners.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;gbdt-and-adaboost&quot;&gt;GBDT and AdaBoost&lt;/h2&gt;

&lt;p&gt;Adaboost and GBDT are both boosting model. So what’s the difference between them?&lt;/p&gt;

&lt;p&gt;For Adaboost, it compute the weight for each instance based on the previous prediction, and assign more weight on those which are wrongly classified and assign low penalty to those classified correctly. Actually, the intuition of Bootstrap and Adaboost are the same. But what about GBDT? GBDT is to learn the residual function of previous prediction. In some ways, you can think about it as learning something that is hard to learn.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;shrinkage&quot;&gt;Shrinkage&lt;/h2&gt;

&lt;p&gt;Shrinkage can be viewed as a competitive regularization method for boosting. The idea behind shrinkage is more little steps towards final result is better/less likely to overfitting than large steps towards optimal. It just assure that each tree may only learn part of truth. And multiple trees can learn better.&lt;/p&gt;

&lt;p&gt;No Shrinkage:&lt;/p&gt;
&lt;center&gt;
$$
y_{n+1} \to residual(\sum_{i=1}^n y_i)\\
y_{pred} = sum(y1,..., y_{n+1})
$$
&lt;/center&gt;
&lt;p&gt;With shrinkage:&lt;/p&gt;
&lt;center&gt;
$$
y_{n+1} \to residual(\sum_{i=1}^n y_i)\\
y_{pred} = sum(y1,..., y_{n}) + step *y_{n+1}
$$
&lt;/center&gt;
</description>
        <pubDate>Mon, 12 Aug 2019 13:12:00 +0800</pubDate>
        <link>http://localhost:4000/posts/gbdt-explanation</link>
        <guid isPermaLink="true">http://localhost:4000/posts/gbdt-explanation</guid>
      </item>
    
      <item>
        <title>Segmentation Related Models and Loss</title>
        <description>&lt;p&gt;In this post, we will cover about some techniques about image segmentation, from FCN to DeepLab, from cross entropy loss to lovász-softmax loss and so on.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;models&quot;&gt;Models&lt;/h2&gt;

&lt;h3 id=&quot;fully-convolutional-net&quot;&gt;Fully Convolutional Net&lt;/h3&gt;

&lt;p&gt;The first model is Fully Convolutional Nets(FCN) [1]. The main contribution of FCN can be three folds:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Without any fully connected layers.&lt;/li&gt;
  &lt;li&gt;Enlarge the size of image: deconvolutional layer.&lt;/li&gt;
  &lt;li&gt;Skip structure; ensemble various depth features.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/segment_topics/fcn.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Without using any DNN layers, FCN allows us to receive different size of images. Besides, FCN provides us with some upsampling methods, since we need to enlarge the size of feature map into original image size.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;h3 id=&quot;upsample&quot;&gt;Upsample&lt;/h3&gt;

  &lt;p&gt;In the application of computer vision, after the feature extraction by CNN, the output data will usually become smaller (mainly due to pooling operation). However, sometimes we want the size of our output images can be exactly the same as input images. Hence, the operation to enlarge the size of image into higher resolution projection is called upsample.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here, we only focus on Transposed convolution. Actually, deconvolution is a special convolutional operation. If we defold the input images as one dimensional vector $X$ and the output images as the same $Y$, the convolutional operation can be represented as $Y = CX$, which is to say, the deconvolution can be rewriten as $X = C^TY$. Finally, what we do is to pad zeros around center points and perform new convolutional operations.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;As we mentioned before, deconvolutional operation can not extactly recover original information, even with the same filter parameters(actually is a non-inversable). This means FCN is unable to maintain positional information for each pixel. There are two totally different ways to tackle with this issue:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Encoder-Decoder Framework, and enable shortcut connection between encoder and decoder. U-Net is one of those classical models.&lt;/li&gt;
  &lt;li&gt;Apply dilated/atrous convolutions, which enables us to remove pooling layers.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;u-net&quot;&gt;U-Net&lt;/h3&gt;

&lt;p&gt;The structure of U-Net[2] is simple as well.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/segment_topics/unet.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Briefly, there are two main points that makes U-Net peforms better than FCN, IMO.&lt;/p&gt;

&lt;p&gt;Firstly, FCN applys summeration for multiple feature maps while U-Net chooses concatenation. Mathematically, summeration will lose information, right?&lt;/p&gt;

&lt;p&gt;Another point is concatenation enables U-Net to consider more global, but worse resolution as well as more local but better resolution information.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;deeplab-v3&quot;&gt;DeepLab v3&lt;/h3&gt;

&lt;p&gt;DeepLab[3] removes pooling layers and replaces it with dialated convolutions. The dialated/atrous convolution can be illustrated as following figures:&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/images/segment_topics/deeplab_1.png&quot; height=&quot;200&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;i&gt;Atrous convolution with kernel size 3 × 3 and different rates. Standard convolution corresponds to atrous convolution with rate = 1. Employing large value of atrous rate enlarges the model’s field-of-view, enabling object encoding at multiple scales.&lt;/i&gt;&lt;/center&gt;

&lt;p&gt;The main contribution of DeepLabv3 System is listed as follows:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;employ atrous convolution in cascade or in parallel to capture multi-scale context by adopting multiple scales.&lt;/li&gt;
  &lt;li&gt;Advanced &lt;em&gt;Atrous Spatial Pyramid Pooling&lt;/em&gt; module, which probe convolutional features at mutiple scales, with image-level features encoding global context.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The above points are proposed to deal with two challenges:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Multiple Pooling or convolution worse the feature resolution, which leads to the uncertainty of positional information.&lt;/li&gt;
  &lt;li&gt;Multiple scale objects in the same images.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/segment_topics/deeplab_2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/segment_topics/deeplab_3.png&quot; /&gt;&lt;/p&gt;

&lt;center&gt;&lt;i&gt;Parallel modules with atrous convolution (ASPP), augmented with image-level features.&lt;/i&gt;&lt;/center&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;some-thoughts-about-these-models&quot;&gt;Some Thoughts about These Models&lt;/h3&gt;

&lt;p&gt;For most Kaggle image segmentation competitions, you will find U-Net is probably the most popular framework , not one of. The reason of this can be concluded:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;U-Net itself is one competitve model in image segmentation.&lt;/li&gt;
  &lt;li&gt;Actually, U-Net provides us with a extendable framework, an encoder-decoder framework, which enables us to replace the encoder/decoder structure with different architecture, like ResBlock, SENet or EffientNet. The easiness of U-Net to ensemble other advanced framework is probably the most important reason that makes it so popular.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;loss&quot;&gt;Loss&lt;/h2&gt;

&lt;p&gt;The loss in image segmentation is also an important topic. The extremely imbalanced positive dataset poses great challenges to our training phase. A carefully designed loss can benefit you with better performance.&lt;/p&gt;

&lt;h3 id=&quot;log-loss&quot;&gt;Log Loss&lt;/h3&gt;

&lt;p&gt;The log loss is actually binary cross entropy loss, which is widely used in binary classificaiton tasks. The formula can be written as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L = -y \cdot log(y') - (1-y)\cdot log(1-y)&lt;/script&gt;

&lt;p&gt;However, this loss function holds an evident drawback: when the positive samples are much less than negative samples, the model can not learn very well from positive samples due to lack of information.&lt;/p&gt;

&lt;h3 id=&quot;dice-loss&quot;&gt;DICE Loss&lt;/h3&gt;

&lt;p&gt;Firstly, we will define the similarity between two shapes. We use A, B to denote the points inside these two shapes. Then,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;DSC(A, B) = 2 \lvert A \cap B\lvert / \lvert A \cup B \lvert&lt;/script&gt;

&lt;p&gt;So the loss can be written as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;DL_2 = 1 - \frac{\sum_{n=1}^Np_n r_n + \epsilon}{\sum_{n=1}^N p_n + r_n + \epsilon} - \frac{\sum_{n=1}^N(1-p_n)(1-r_n)+\epsilon}{\sum_{n=1}^N2-p_n-r_n + \epsilon}&lt;/script&gt;

&lt;p&gt;Here is an implementation with Keras&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;dice_coef&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;smooth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;intersaction&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_true&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;union&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;intersection&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;smooth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;union&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;smooth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;dice_coef_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dice_coef&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;smooth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;focal-loss&quot;&gt;Focal Loss&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
f(n) = \begin{cases} -(1-y')^\gamma \text{log}y', &amp;\text{if y=1} \\ -y'^\gamma\text{log}(1-y'), &amp; \text{if y=0}\end{cases} %]]&gt;&lt;/script&gt;

&lt;p&gt;In focal loss, we focus more on samples which is hard to classify, and assign low penalty to those samples which is easier. Take $\gamma = 2 $ as an example,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;for positive samples, if our prediction is 0.97, then it must be an easy-to-classify sample, hence $(1-0.97)^\gamma$ will be very small. On the contrary, if our prediction is 0.3, then it would be a hard-to-classify sample, then $(1-0.3)^\gamma$ will be quite large (at least larger than the previous one)&lt;/li&gt;
  &lt;li&gt;vice versa&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Additionally, focal loss also use $\alpha$, called balance factor to balance the distribution between positive and negative samples.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
f(n) = \begin{cases} -\alpha (1-y')^\gamma \text{log}y', &amp;\text{if y=1} \\ -(1-\alpha)y'^\gamma\text{log}(1-y'), &amp; \text{if y=0}\end{cases} %]]&gt;&lt;/script&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;focal_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.75&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.25&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;pt_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;where&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;equal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;pt_0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;where&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;equal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
  
  &lt;span class=&quot;n&quot;&gt;pt_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pt_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;.999&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;pt_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pt_0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;.999&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pt_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pt_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pt_0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pt_0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;lovasz-softmax-loss&quot;&gt;Lovasz-Softmax Loss&lt;/h3&gt;

&lt;p&gt;IoU (Jaccard index) is actually intractable, since it needs equal operation. However, Jaccard loss can be performed with Lovasz extension, which enables discrete space into continuous space, which will be tractable.&lt;/p&gt;

&lt;p&gt;BTW, lovasz-softmax loss is used during fine-tuning phase. A common practice is to train the model with BCE loss/ DICE loss a few epochs and then turn the loss to Lovasz loss + DICE/BCE loss.&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;p&gt;[1] &lt;a href=&quot;https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf&quot;&gt;Fully Convolutional Networks for Semantic Segmentation&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[2] &lt;a href=&quot;https://arxiv.org/abs/1505.04597&quot;&gt;U-Net: Convolutional Networks for Biomedical Image Segmentation&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[3] &lt;a href=&quot;https://arxiv.org/abs/1706.05587&quot;&gt;Rethinking Atrous Convolution for Semantic Image Segmentation&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[4] &lt;a href=&quot;www.kaggle.com&quot;&gt;Kaggle: A Data Competition Platform&lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Fri, 09 Aug 2019 13:43:00 +0800</pubDate>
        <link>http://localhost:4000/posts/segmentation-related</link>
        <guid isPermaLink="true">http://localhost:4000/posts/segmentation-related</guid>
      </item>
    
      <item>
        <title>Revisiting Variational Autoencoder</title>
        <description>&lt;p&gt;Given examples X distributed according  to some unknown distribution $P_{gt}(X)$, the goal is to learn a model $P$ which we can sample from, such that $P$ is as similiar as possible to $P_{gt}$.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;drawbacks-of-existed-methods&quot;&gt;Drawbacks of existed methods&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;require strong assumptions about the structure in the data&lt;/li&gt;
  &lt;li&gt;make severe approximations, leading to suboptimal models&lt;/li&gt;
  &lt;li&gt;rely on computationally expensive inference procedures like Markov Chain Monte Carlo.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;maximum-likelihood-estimation&quot;&gt;Maximum Likelihood Estimation&lt;/h2&gt;

&lt;p&gt;Beforer starting VAE, we would like to revisit the relationship between maximum likelihood and KL divergence. So, if we are interested in estimating a true distribution $p(x)$, we introduce a set of candidate distributions $\mathcal{P}_x$. Hence, though we don’t have an access to the true distirbution $p^*(x)$, we do have the access to finite samples from $\mathcal{P}_x$. We denote uniform sampling from this finite dataset as $\hat{p}(x)$. The goal of maximum likelihood estimation is to find the best $p \in \mathcal{P}_x$ to approximate $p^(x)$ as measured by the Kullback-Leibler divergence,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min \limits_{p\in\mathcal{P}_x} D(\hat{p}||p_g) = \min \limits_{p\in\mathcal{P}_x}\mathbb{E}_{\hat{p}(x)} \displaystyle \left[{\rm In}\frac{\hat{p}(x)}{p(x)}\right] \\ \equiv \max_{p\in \mathcal{P}_x}\mathbb{E}_{\hat{p}(x)}[{\rm In} p(x)]&lt;/script&gt;

&lt;p&gt;From the above, we can find that mimizing the KL divergence is equalvalent to maximizing the log likelihood.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;goal&quot;&gt;Goal&lt;/h2&gt;

&lt;p&gt;Maximize the probability of each X in the training set under the entire generative process,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(X) = \int P(X|z; \theta)P(z)dz&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;In terms of the shape of $z$, Gaussian distribution is ok since any distribution in $d$ dimension can be generated by taking a set of $d$ variables that are normally distributed and mapping them through a sufficiently complicated function.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The second problem is to maximize $P(X)$. An intuitive idea is sample points $z_i$ from $P(z)$ and then to approximate $P(X)$ with&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{i=0}^{n}P(X|z_i)&lt;/script&gt;

    &lt;p&gt;However, this is highly compuationally. VAE alters the sampling procedure.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;most-interesting-part&quot;&gt;Most Interesting Part&lt;/h2&gt;

&lt;h3 id=&quot;setting-the-objective&quot;&gt;Setting the objective&lt;/h3&gt;

&lt;p&gt;For most $z$, $P(X\lvert z)$ provide no information to our estimate of $P(X)$. The key idea of VAE is to sample values of $z$ that are likely to have produces $X$ and compute $P(X)$ just from those. More specially, we need a new function $Q(z\lvert X)$ which can take a value of $X$ and give us a distribution over $z$. Since the space of $z$ values that are likely under $Q$ is much smaller than the space of all $z$ s that are under the prior $P(z)$. Therefore, our task becomes to compute $E_{z	\in Q}P(X\lvert z)$ and relate it with $P(X)$.&lt;/p&gt;

&lt;p&gt;The relationship between $E_{z\in Q}P(X\lvert z)$ and $P(X)$ can be measured by KL divergence or $\mathcal{D}$.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{D}[Q(z)||P(z|X)] = E_{z\in Q}[{\rm log}Q(z) - {\rm log}P(z|X)]&lt;/script&gt;

&lt;p&gt;By applying Bayes rule to $P(z\lvert X)$:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{D}[Q(z)||P(z|X)] = E_{z\in Q}[{\rm log}Q(z) - {\rm log}P(X|z) - {\rm log}P(z)] + {\rm log}P(X)&lt;/script&gt;

&lt;p&gt;Negating both sides, rearranging, we can get:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{\rm log}P(X) - \mathcal{D}[Q(z)||P(z|X)] = E_{z\in Q}[{\rm log}P(X|z)] - \mathcal{D}[Q(z)||P(z)]&lt;/script&gt;

&lt;p&gt;Since we are interested in infering $P(X)$, it makes sense to construct a $Q$ which does depend on $X$, and in particular, one which makes $\mathcal{D}[Q(z)\lvert \lvert P(z\lvert X)] $ small:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{\rm log}P(X) - \mathcal{D}[Q(z|X)||P(z|X)] = E_{z\in Q}[{\rm log}P(X|z)] - \mathcal{D}[Q(z|X)||P(z)]&lt;/script&gt;

&lt;p&gt;Until now, we reach the core of the variational autoencoder. The left term have the quantity we want to maximize: ${\rm log}P(X)$ plus an error term. The right hand is something that we can optimize through stochastic gradient descent. Let have a deeper look at the rigth hand term.&lt;/p&gt;

&lt;p&gt;$E_{z\in Q}[{\rm log}P(X\lvert z)]$ enforces that we want the conditional X can be well reconstructed with sampled $z$, besides, $z$ was generated or sampled from distribution $Q$. And $\mathcal{D}[Q(z\lvert X)\lvert \lvert P(z)]$ is to force the Q to be similar to P. If we put these constraints into an autoencoder framework, it is quite natural to view  $P$ as decoder and $Q$ as encoder.&lt;/p&gt;

&lt;h3 id=&quot;optimizing-the-objective&quot;&gt;Optimizing the objective&lt;/h3&gt;

&lt;p&gt;Firstly, what the form that $Q(z\lvert X)$ will take? The usual choice is to say that $Q(z\lvert X)$ follows an Gaussian distribution $\mathcal{N}(z\lvert \mu(X,\theta), \sum(X, \theta))$. Since we have already assumed that $P(z)$ can be viewed as an Gaussian distribution, the last term $\mathcal{D}[Q(z\lvert X)\lvert\lvert P(z)]$ is now a KL-divergence between two Gaussian distribution.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{D}[\mathcal{N}(\mu(X), \Sigma(X))||\mathcal{N}(0, I)] \\=\frac{1}{2}(tr(\Sigma(X))+(\mu(X))^T(\mu(X)) - k - {\rm log}det(\Sigma(X)))&lt;/script&gt;

&lt;p&gt;where $k$ is the dimensionally of the distribution.&lt;/p&gt;

&lt;p&gt;Suppose we are doing stochastic gradient descent over different values of $X$ sampled from a dataset $D$, the full equation here can be rewrited as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;E_{X\in D}[{\rm log}P(X) - \mathcal{D}[Q(z\lvert X)\lvert \lvert P(z \lvert X)]] = \\ E_{X\in D}[E_{z\in Q}[{\rm logP(X\lvert z)}] - \mathcal{D}[Q(z\lvert X)\lvert \lvert P(Z)]]&lt;/script&gt;

&lt;p&gt;If we compute the gradient of the right term, $Q(z\lvert X)$ is  untractable. Though we may sample $z$ for forward propagation but this sampling can not propogate back, which is a non-continuous operation and has no gradient. To tackle with this issue, the solution, called “reparameterization trick” was proposed to move the sampling into an input layer. Given $\mu(X)$ and $\Sigma(X)$, we can sample from $\mathcal{N}(\mu(X), \Sigma(X))$ by first sampling $\epsilon$ from $\mathcal{N}(0, I)$, then computing $z = \mu(X)+\Sigma^{1/2}(X)\cdot \epsilon$.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/revisiting_vae/vae.png&quot; /&gt;&lt;/p&gt;

&lt;center&gt;&lt;i&gt;Figure: A training-time variational autoencoder implemented as a feedforward neural network, where $P(X\lvert z)$ is Gaussian. Left is without the “reparameterization trick”, and right is with it. Red shows sampling operations that are non-differentiable. Blue shows loss layers. The feedforward behavior of these networks is identical, but backpropagation can be applied only to the right network.&lt;/i&gt;&lt;/center&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;p&gt;[1] &lt;a href=&quot;https://arxiv.org/abs/1606.05908&quot;&gt;Tutorial on Variational Autoencoders&lt;/a&gt;(https://arxiv.org/abs/1606.05908)&lt;/p&gt;

&lt;p&gt;[2] &lt;a href=&quot;http://ruishu.io/2018/03/14/vae/&quot;&gt;DENSITY ESTIMATION: VARIATIONAL AUTOENCODERS&lt;/a&gt; (http://ruishu.io/2018/03/14/vae/)&lt;/p&gt;
</description>
        <pubDate>Fri, 02 Aug 2019 16:52:00 +0800</pubDate>
        <link>http://localhost:4000/posts/revisit-variational-autoencoder</link>
        <guid isPermaLink="true">http://localhost:4000/posts/revisit-variational-autoencoder</guid>
      </item>
    
  </channel>
</rss>
